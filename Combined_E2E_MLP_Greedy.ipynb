{"cells":[{"cell_type":"markdown","metadata":{"id":"0ba86871"},"source":["##### Load Wikitext dataset (please run!)"],"id":"0ba86871"},{"cell_type":"markdown","metadata":{"id":"8LbF0QkbhDYL"},"source":["Headings without any text below it (i.g. only table) are excluded."],"id":"8LbF0QkbhDYL"},{"cell_type":"code","execution_count":null,"metadata":{"id":"aucLqNev5jNX"},"outputs":[],"source":["%%capture\n","!pip install datasets\n","!pip install numpy\n","!pip install pandas\n","!pip3 install http://download.pytorch.org/whl/cu92/torch-0.4.1-cp36-cp36m-linux_x86_64.whl\n","!pip3 install torchvision"],"id":"aucLqNev5jNX"},{"cell_type":"code","execution_count":null,"metadata":{"id":"bfb33fc8"},"outputs":[],"source":["import datasets\n","from datasets import load_dataset, list_datasets\n","import pandas as pd \n","import re \n","import numpy as np "],"id":"bfb33fc8"},{"cell_type":"code","execution_count":null,"metadata":{"id":"3bb659e0"},"outputs":[],"source":["class Node(object):\n","    '''\n","    each node contains \n","    - parent \n","    - children \n","    - text\n","    '''\n","    def __init__(self,txt: str, level:int):\n","        self.text = txt \n","        self.level = level\n","        self.parent = None \n","        self.children = []\n","    def insertChild(self,child):\n","        self.children.append(child)\n","    def linkParent(self, parent):\n","        if(self.parent != None):\n","            print(\"ERROR: node \", self.text, \"already has a parent\")\n","        else:\n","            self.parent = parent \n","            \n","        \n","class Tree(object):\n","    def __init__(self,document):\n","        self.root = Node(document['title'],level=0)\n","        self.depth = np.amax([v['type'] for v in document['document']], initial=0)\n","        curNode = self.root \n","        # para of format {\"text\", \"type\"}\n","        for para in document['document']:\n","            newNode = Node(para['text'],para['type'])\n","            \n","            # growing in depth\n","            if(newNode.level == -1 or newNode.level > curNode.level):\n","                curNode.insertChild(newNode)\n","                newNode.linkParent(curNode)\n","                if(newNode.level > 0):\n","                    curNode = newNode \n","                \n","            # new heading belong to the same or lower level of subheading \n","            else: \n","                # trace back to the heading level that new heading is immediately under \n","                while(curNode.level>=newNode.level):\n","                    curNode = curNode.parent\n","                curNode.insertChild(newNode)\n","                newNode.linkParent(curNode)\n","                curNode = newNode \n","        return \n","    \n","    def printTree(self):\n","        print(\"======== PRINTING TREE =========\")\n","        print(\"TITLE: \", self.root.text)\n","        print(\"MAX DEPTH: \", self.depth)\n","        print(\"===============================\")\n","        def printNode(curNode):\n","            print(curNode.text)\n","            if(curNode.level == -1):\n","                return \n","            \n","            for child in curNode.children:\n","                printNode(child)\n","            return \n","        printNode(self.root)\n","        \n","    \n","\n","        "],"id":"3bb659e0"},{"cell_type":"code","execution_count":null,"metadata":{"id":"f09a8de0"},"outputs":[],"source":["## helper functions \n","\n","# get type of text \n","def checkHeading(txt):\n","    if(txt == ''):\n","        return -2\n","    if(re.search(r'^\\s=.+\\s=\\s\\n',txt)):\n","        return int(len(re.findall(r'\\s=',txt))/2 - 1)\n","    return -1 \n","\n","# load documents to feed to tree \n","def createDocuments(data):\n","    documents_with = []\n","    documents_without = []\n","    document_with = []\n","    document_without = []\n","    curTitle = ''\n","    for i in data:\n","        c = checkHeading(i)\n","        if(c==-2):\n","            continue\n","        if(c>-1):\n","            # strip heading \n","            i = re.findall(r'=\\s([^=]+)\\s=', i)[0]\n","        if(c==0):\n","            \n","            # clear out empty headings \n","            while(len(document_with)>1 and document_with[-1]['type']!=-1):\n","                document_with.pop(-1)\n","            documents_with.append({'title': curTitle, 'document':document_with})\n","            documents_without.append(document_without)\n","            curTitle = i\n","            document_with = []\n","            document_without = []\n","            \n","        else:\n","            # clear out empty headings GOOFY HELP HOW TO CLEAN THIS UP \n","            if(len(document_with)>1 and document_with[-1]['type']!=-1 and c <= document_with[-1]['type'] and c!=-1):\n","                document_with.pop(-1)\n","            document_with.append({'text':i,'type':c})\n","            if(c==-1):\n","                document_without.append(i)\n","            \n","    documents_with.pop(0)\n","    documents_without.pop(0)\n","    return documents_with, documents_without"],"id":"f09a8de0"},{"cell_type":"markdown","metadata":{"id":"e7ac6222"},"source":["loadData() creates a list of data points containing the title of article, raw text (paragraphs), and the tree representation of heading structures."],"id":"e7ac6222"},{"cell_type":"code","execution_count":null,"metadata":{"id":"e6f4ecfe"},"outputs":[],"source":["## load wiki dataset \n","def loadData(train = False, min_size=-1):\n","    \"\"\"\n","    prepare dataset for training, which is a list of dictionaries containing:  \n","    - document title (string)\n","    - paragraphs (list of string)\n","    - tree representation of headings\n","    \"\"\"\n","    \n","    data_raw = load_dataset(\"wikitext\",'wikitext-103-v1',split='train' if train else 'test')\n","    data_raw = data_raw['text']\n","    documents_with, documents_without = createDocuments(data_raw)\n","    \n","    data = []\n","    i = 0\n","    for document in documents_with:\n","        tree = Tree(document)\n","        if len(documents_without[i]) < min_size:\n","          continue\n","#         tree.printTree()\n","        data.append({\n","            \"title\":document['title'],\n","            \"paragraphs\":documents_without[i],\n","            \"tree\": tree\n","        })\n","        i+=1\n","    return data    "],"id":"e6f4ecfe"},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","referenced_widgets":["773c05cde4a1423084d64f142850fb1d","5a035187b68a4a0e97bfafcd5d0d91e8","a48ee359b4734d87b9ec8f639d04ad23","617dbcb8028c4675b5c48b14fe46f08c","775b015c91494f02bc04279af272ab13","6283bf621bb74c64a67e8a6867d39911","f4564b7c56c648ad97336aecd26ed33b","7f6d7177f8914ca6b08d53ed2b67325d","c7bb305976464830b25a298654a64604","58153034028348caafa8b6c6d1bee89d","28573a80e4e84cf98e8440741056b053","ac2ced3866624559875d294050f60152","281df3a0fc9341b3a1fba2ed4efa930e","ced9c087cf724e47a74f6211a013d351","cbfc2c011d3e427883520fcfa996a271","43c7e087e9564d8d9477806887c484f9","815ba480181349dd825187d2cef43aa8","54ac043dc38f4bb4957f4d7f7657b994","60b755cd7e7a41ecbc56153205cd1ac0","03a4f14226464f908f54aded4531ee08","fc1d31374d4e4385a0f978a2d1e36e8b","121f83539f8a4b26931ecb5feb5e3977","25f34817536b49dca5ec9885360f7dd0","f8f2ea1cbfb643ccb94f40049654ca86","9732984f8eec46c9b5213c7d8caf8aeb","ea7f1b60234e4348b9920936ab199116","246a5ad76b5e46678f44c9b595622ac4","5200df879aa5458f9ba6e1d8da9f551d","fa7b28759a9f4d7784c403f11615aa3c","7d77a583d7fc422ea465c646b1d418f9","4b43456002264dbda81e4f3ce5e15e38","ef7743c0475040c3bbc62e24f144534b","fed88e05d29d4eaf9bb9a7fbe91e8fcd","23fcd87df73a417294b1276d5bdd5ac1","e04edd5502644d47b931910271d238ba","308a4b948cd84ba492a45d5892233c21","d2f00a6d90dd47d290fc754fecc6a4b1","9fd0a1596ed04a0c8be5e81f65ea01e0","e5b5591d62e54a238880fb1acb6dcf4d","9353f028be9446b4adf08246b2c369d9","acb06e8008fb4260a78c5472afcbf0e6","c376ae4317984cd685aea994822a499e","76e3856ed53e48aea8e8ba8d506cb7b4","6f5551025d1b44dcac4f68dbd4f194d8","8577544779b84b0b89148142a95384cd","6b7ef23c58d945cea9187fa9388c37e8","cb771726df0b48d7a761901434b125cd","6d5a0ac5920d417282f359a0c8b06baf","ea50b4f5786347649809f72f76295684","bbf48b5c77684dd19033e3435435045d","b6a309452d6a4355a405ed2dd1adae82","2a20a51c8b214be896e710cf49218ee4","554c9581fc654bfab759605a135179fb","83c598bf65c5414a94806ef20cf693fc","3137f59faf16438eaff31e134bd719bf","38736a24e576459c93e31f35192abe10","6555fb7e67614def8396ee1ed8e7a96e","8ec81ddfdd1947d098dfd905a19a65bb","bf10e5be7bae432395134f7baaf8ab18","f905ad9adce24720a615e1ae9113fab8","328d7ceac2374478b88d1b7fd979ce36","4d12722f87fc45fa94a5330a48830a2a","0396dc796df344a29814e80aac8bf309","b4e8e94f0fc949129ad2a824edfc5873","5c4bc994762c446ba9189109c426999c","d070834acdb643cb853fa60f8ebc7aec"]},"executionInfo":{"elapsed":106702,"status":"ok","timestamp":1651532610577,"user":{"displayName":"Michael Tang","userId":"18009171711496870090"},"user_tz":240},"id":"de5fbda0","outputId":"a5012884-32e3-42fd-d925-e501951c5aac","scrolled":true},"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading builder script:   0%|          | 0.00/2.03k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"773c05cde4a1423084d64f142850fb1d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading metadata:   0%|          | 0.00/1.25k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ac2ced3866624559875d294050f60152"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Downloading and preparing dataset wikitext/wikitext-103-v1 (download: 181.42 MiB, generated: 522.23 MiB, post-processed: Unknown size, total: 703.64 MiB) to /root/.cache/huggingface/datasets/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126...\n"]},{"output_type":"display_data","data":{"text/plain":["Downloading data:   0%|          | 0.00/190M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"25f34817536b49dca5ec9885360f7dd0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Generating test split:   0%|          | 0/4358 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"23fcd87df73a417294b1276d5bdd5ac1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Generating train split:   0%|          | 0/1801350 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8577544779b84b0b89148142a95384cd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Generating validation split:   0%|          | 0/3760 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"38736a24e576459c93e31f35192abe10"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Dataset wikitext downloaded and prepared to /root/.cache/huggingface/datasets/wikitext/wikitext-103-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126. Subsequent calls will reuse this data.\n"]}],"source":["data = loadData(train=True)"],"id":"de5fbda0"},{"cell_type":"markdown","metadata":{"id":"48ec35e7"},"source":["testing: compared tree pre-order traversal of 10 documents with raw data. No bug. "],"id":"48ec35e7"},{"cell_type":"markdown","metadata":{"id":"e49e36c2"},"source":["##### Training set statistics"],"id":"e49e36c2"},{"cell_type":"markdown","metadata":{"id":"szkFxU2gg_zd"},"source":["Include stats of  \n","- number of paragraphs per article  \n","- average length of paragraphs per article \n","- maximum depth of articles  "],"id":"szkFxU2gg_zd"},{"cell_type":"code","execution_count":null,"metadata":{"id":"abf1a160"},"outputs":[],"source":["from matplotlib import pyplot as plt \n","import numpy as np\n","import scipy.stats as stats\n","def getStat(data):\n","    # number of paragraphs per article \n","    num_para = np.array([len(x['paragraphs']) for x in data])\n","    counts, edges, bars = plt.hist(num_para,40)\n","    print(\"========= number of paragraphs per article========\")\n","    print(pd.Series(num_para).describe())\n","    plt.show()\n","    \n","    # number of sentences per paragraph \n","    para_lens = []\n","    for d in data:\n","        paras = d['paragraphs']\n","        for para in paras:\n","            lgh = len(para.split('.'))-1\n","            para_lens.append(lgh)\n","    print(\"========= number of sentences per paragraph========\")\n","    print(pd.Series(para_lens).describe())\n","    _,_,_ = plt.hist(para_lens,40)\n","    plt.show()\n","\n","    \n","    # depth of articles \n","    depths = [d['tree'].depth for d in data]\n","    print(\"========= maximum depth of articles========\")\n","    print(pd.Series(depths).describe())\n","    _,_,_ = plt.hist(depths)\n","    plt.show()\n","\n","    return \n","    "],"id":"abf1a160"},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":1935,"status":"ok","timestamp":1651456990591,"user":{"displayName":"Evan Dogariu","userId":"08207052186530176995"},"user_tz":240},"id":"b1e3193c","outputId":"82424945-f8dd-4fc2-8775-f1e502c37af7"},"outputs":[{"name":"stdout","output_type":"stream","text":["========= number of paragraphs per article========\n","count    29444.000000\n","mean        29.206052\n","std         25.829840\n","min          1.000000\n","25%         12.000000\n","50%         21.000000\n","75%         37.000000\n","max        284.000000\n","dtype: float64\n"]},{"data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["========= number of sentences per paragraph========\n","count    859943.000000\n","mean          4.830331\n","std           3.650685\n","min           0.000000\n","25%           2.000000\n","50%           4.000000\n","75%           7.000000\n","max          75.000000\n","dtype: float64\n"]},{"data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["========= maximum depth of articles========\n","count    29444.000000\n","mean         1.758355\n","std          0.686543\n","min          0.000000\n","25%          1.000000\n","50%          2.000000\n","75%          2.000000\n","max          5.000000\n","dtype: float64\n"]},{"data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["getStat(data)"],"id":"b1e3193c"},{"cell_type":"markdown","metadata":{"id":"FSKtCnA_BdMD"},"source":["##### Preparing SimCSE and Doc2Vec embeddings + related setup (please run!)"],"id":"FSKtCnA_BdMD"},{"cell_type":"code","execution_count":null,"metadata":{"id":"Qkh6gZxswMUB"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n","import random\n","random.seed(10)\n","torch.manual_seed(0)\n","np.random.seed(0)\n","import re\n","import time\n","import math\n","from IPython.utils import io"],"id":"Qkh6gZxswMUB"},{"cell_type":"code","execution_count":null,"metadata":{"id":"87baa622"},"outputs":[],"source":["%%capture\n","!pip install simcse"],"id":"87baa622"},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":177,"referenced_widgets":["ef2bc51cf1a84b1ca856c4e265879cf5","85cf1d77f0924327a1eb95afc7fd3011","3895e3a6bec444eabe862f82249b319c","9708ea704f4b4f4cbfb52ef3533f05ed","8eb0742b4d1048e4a1ee11913bd3cdbf","25faf5e68c454d3e9ded128f3a1a537e","d705ca2543544fe4a7aec25c1a5a53ca","d697581694454f588965a608fb5b5e02","413c070a006a46bfa9125bfb93fc1a0b","59c0542f6cb34181b1d2e7010bffe36e","172d08811d284c138881787a07859fd3","224ab8eedf1d436083fd2bf54bc1a9d9","2176a90bbe5d47069b5d5f44e08b8ac2","b44f1e298fce4d1d8d25b5efa006af64","3c0fcc03e47740f09c7462cb3190188f","6d4926ec931647b684fae41439ffcd1a","f3c16b5087924db38083f9ecc4c3fd25","65852eadf5394ba0a3b088937ea48651","128db6e92c2f480d8e682913538c28a5","15f96380e4bf45c59310f39b3c7dc10c","a3aa988f39c9463a978171fe47b1d022","f963ceae2bb44d66b951cb8f20c76a78","58c6ff8c2944417f985d2e6bb6a539cf","2f716f49f76e4d51a0fc81cc4e9d1002","05c5f215ed7d43d3b7b5485c9a2da38f","6cdb0e41acee4351add7fe639ca8a591","ad4139224d064426abff47547e5e8927","ad4cef694b7e43e188393ee353796f2c","e94be5614c4a4eeb832b4f1f3cb4c418","f4479572e309462d96d13122ccf24e3a","60e74ade881f4c11b6f47bd5777c2e21","20a73804ccad418a8c02cd878680aa19","651f69f0e1b44e66acdae3edd30c631b","8fcb5f59868e47a2b3e5276b481630e9","0a610eee469f41888a6e4455ffbc8018","606f1faa202d4a788d254832e7f61dbb","5066f23abdc0484b8c80faa56b022872","ea7ac9d8672a45ceb82db8b3385fa8df","f58aef5744db4c1e8e4048a99562687f","bc20ab5ab26b407ea31d84ed96cff1d2","866b50cc44d4466c9faec5724eafa112","e1e03e4c95d24426badad309112f27de","fa0e2ddcc81e476499c34910a3cdd184","ba143d5633884e258e366af7c5fc8742","f635f543ed3343cabb57e4cc47dcb0d0","eb7b58eace194f739177fc7afb6e61c1","ab7b8c1bbb1045a0a0572f4489a20bda","714e39edacbb4986947fb5ded0945149","d7f49f3c81f843999972c334434b90fa","dcc30d7944a34fc0bbd64844620d9e78","629a769e931f45acb6727bbe203aa4a2","204e29c8a78e4be3bd33432c86de43c9","23c1777fb6bd4c11afec127b45c24e06","6c149eb091c84007ac2935c1262b5695","4e5ee2f003e94e3083a19c450db40ad1"]},"executionInfo":{"elapsed":38242,"status":"ok","timestamp":1651532682049,"user":{"displayName":"Michael Tang","userId":"18009171711496870090"},"user_tz":240},"id":"szpU2OFCB3s0","outputId":"1b1ad574-8704-4c2a-c75f-5e299c0cb9b1"},"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/252 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ef2bc51cf1a84b1ca856c4e265879cf5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/689 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"224ab8eedf1d436083fd2bf54bc1a9d9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/226k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"58c6ff8c2944417f985d2e6bb6a539cf"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/112 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8fcb5f59868e47a2b3e5276b481630e9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/418M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f635f543ed3343cabb57e4cc47dcb0d0"}},"metadata":{}}],"source":["from simcse import SimCSE\n","simcse_model = SimCSE(\"princeton-nlp/sup-simcse-bert-base-uncased\")"],"id":"szpU2OFCB3s0"},{"cell_type":"code","execution_count":null,"metadata":{"id":"mP43IO_uB3wn"},"outputs":[],"source":["# # mini-demo with print suppression\n","# with io.capture_output() as captured:\n","#     print('this should not be printed')\n","#     embeddings = simcse_model.encode(\"A woman is reading, and a man is here\")\n","# print('this should be printed')\n","# print(embeddings.shape)"],"id":"mP43IO_uB3wn"},{"cell_type":"code","execution_count":null,"metadata":{"id":"zmqyWpNGmruU"},"outputs":[],"source":["SIMCSE_DIM = 768\n","MAX_DEPTH = 8\n","# MAX_PARAS = 300\n","# MAX_SENTS_PER_PARA = 80"],"id":"zmqyWpNGmruU"},{"cell_type":"code","execution_count":null,"metadata":{"id":"ThJG0MPafOBW"},"outputs":[],"source":["# for segmentation\n","START_IDX = 0\n","END_IDX = MAX_DEPTH"],"id":"ThJG0MPafOBW"},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":31208,"status":"ok","timestamp":1651532713249,"user":{"displayName":"Michael Tang","userId":"18009171711496870090"},"user_tz":240},"id":"0NiXOdkJHcI5","outputId":"44965fda-3ee9-43de-df25-87345af1e945"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting gensim==4.1.2\n","  Downloading gensim-4.1.2-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (24.1 MB)\n","\u001b[K     |████████████████████████████████| 24.1 MB 5.3 MB/s \n","\u001b[?25hRequirement already satisfied: numpy>=1.17.0 in /usr/local/lib/python3.7/dist-packages (from gensim==4.1.2) (1.19.5)\n","Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.7/dist-packages (from gensim==4.1.2) (6.0.0)\n","Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.7/dist-packages (from gensim==4.1.2) (1.5.4)\n","Installing collected packages: gensim\n","  Attempting uninstall: gensim\n","    Found existing installation: gensim 3.6.0\n","    Uninstalling gensim-3.6.0:\n","      Successfully uninstalled gensim-3.6.0\n","Successfully installed gensim-4.1.2\n","Requirement already satisfied: cython in /usr/local/lib/python3.7/dist-packages (0.29.28)\n","Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (3.2.5)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from nltk) (1.15.0)\n","[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n"]}],"source":["!pip install gensim==4.1.2\n","!pip install cython\n","!pip install nltk\n","\n","import nltk\n","nltk.download('punkt')\n","from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n","from nltk.tokenize import word_tokenize"],"id":"0NiXOdkJHcI5"},{"cell_type":"markdown","metadata":{"id":"xBFAl4oVXTj5"},"source":["Train Doc2Vec Encoder (only done once, after that we load from 'd2v.model')"],"id":"xBFAl4oVXTj5"},{"cell_type":"code","execution_count":null,"metadata":{"id":"zb6rnfyOH7jv"},"outputs":[],"source":["# # DONT NEED TO RUN THIS CELL IF U HAVE THE FILES\n","# documents = [d['paragraphs'] for d in data]\n","# paragraphs = []\n","# for doc in documents:\n","#   for p in doc:\n","#     paragraphs.append(p)\n","# # print(len(paragraphs))\n","# tagged_data = [TaggedDocument(words=word_tokenize(_d.lower()), tags=[str(i)]) for i, _d in enumerate(paragraphs)]\n","\n","\n","# max_epochs = 15\n","# vec_size = 128\n","# alpha = 0.025\n","\n","# with io.capture_output() as captured:\n","#     doc2vec_model = Doc2Vec(vector_size=128, min_count=2, window=2, workers=4, dm=1, alpha=alpha, min_alpha=0.00025)\n","#     doc2vec_model.build_vocab(tagged_data)\n","\n","# for epoch in range(max_epochs):\n","#     print('iteration {0}'.format(epoch))\n","#     with io.capture_output() as captured:\n","#         doc2vec_model.train(tagged_data,\n","#                             total_examples=doc2vec_model.corpus_count,\n","#                             epochs=4)\n","#     # decrease the learning rate\n","#     doc2vec_model.alpha -= 0.0002\n","#     # fix the learning rate, no decay\n","#     doc2vec_model.min_alpha = doc2vec_model.alpha\n","\n","# doc2vec_model.save(\"d2v.model\")\n"],"id":"zb6rnfyOH7jv"},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":41173,"status":"ok","timestamp":1651532754403,"user":{"displayName":"Michael Tang","userId":"18009171711496870090"},"user_tz":240},"id":"ANF-NCtImfWz","outputId":"9a69549e-467b-482a-b076-f5315b1ebf42"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"id":"ANF-NCtImfWz"},{"cell_type":"markdown","metadata":{"id":"d9GjBog-n4k4"},"source":["Make sure to add 484-finalProject as shortcut in drive."],"id":"d9GjBog-n4k4"},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":13,"status":"ok","timestamp":1651532754404,"user":{"displayName":"Michael Tang","userId":"18009171711496870090"},"user_tz":240},"id":"jxT9-NNFmvTL","outputId":"933997d3-012f-47cc-970b-ef13b4f3c31e"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/.shortcut-targets-by-id/154EdVBqpeIxqbeun-wGvxSgsYCVV1wdV/484-finalProject\n"]}],"source":["cd /content/drive/My\\ Drive/484-finalProject"],"id":"jxT9-NNFmvTL"},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":17396,"status":"ok","timestamp":1651533012332,"user":{"displayName":"Michael Tang","userId":"18009171711496870090"},"user_tz":240},"id":"04k_YJCVBigD","outputId":"4b25b078-7355-4973-9b43-7a623c25fc19"},"outputs":[{"output_type":"stream","name":"stderr","text":["05/02/2022 23:09:54 - INFO - gensim.utils -   loading Doc2Vec object from models/128_d2v.model\n","05/02/2022 23:09:56 - INFO - gensim.utils -   loading dv recursively from models/128_d2v.model.dv.* with mmap=None\n","05/02/2022 23:09:56 - INFO - gensim.utils -   loading vectors from models/128_d2v.model.dv.vectors.npy with mmap=None\n","05/02/2022 23:10:04 - INFO - gensim.utils -   loading wv recursively from models/128_d2v.model.wv.* with mmap=None\n","05/02/2022 23:10:04 - INFO - gensim.utils -   loading vectors from models/128_d2v.model.wv.vectors.npy with mmap=None\n","05/02/2022 23:10:06 - INFO - gensim.utils -   loading syn1neg from models/128_d2v.model.syn1neg.npy with mmap=None\n","05/02/2022 23:10:09 - INFO - gensim.utils -   setting ignored attribute cum_table to None\n","05/02/2022 23:10:11 - INFO - gensim.utils -   Doc2Vec lifecycle event {'fname': 'models/128_d2v.model', 'datetime': '2022-05-02T23:10:11.848870', 'gensim': '4.1.2', 'python': '3.7.13 (default, Apr 24 2022, 01:04:09) \\n[GCC 7.5.0]', 'platform': 'Linux-5.4.188+-x86_64-with-Ubuntu-18.04-bionic', 'event': 'loaded'}\n"]}],"source":["doc2vec_model= Doc2Vec.load(\"models/128_d2v.model\")"],"id":"04k_YJCVBigD"},{"cell_type":"code","execution_count":null,"metadata":{"id":"E12J-l2eXiM-"},"outputs":[],"source":["# # Experiment with inference and lookups :)\n","# test1 = word_tokenize(\"This is a test of the paragraph embedding model.\".lower())\n","# test2 = word_tokenize(\"I am testing my model to encode paragraphs.\".lower())\n","# test3 = word_tokenize(\"Complete gibberish, baby talk with a model. Goo goo ga ga.\")\n","# test4 = word_tokenize(\"This is a test for my model to embed paragraphs.\".lower())\n","\n","# v = doc2vec_model.infer_vector(test1)\n","# v1 = doc2vec_model.infer_vector(test1)\n","# v2 = doc2vec_model.infer_vector(test2)\n","# v3 = doc2vec_model.infer_vector(test3)\n","# v4 = doc2vec_model.infer_vector(test4)\n","# print(np.linalg.norm(v1 - v))  # normal inference, turns tokenized, lowercase paragraph into 128-vector\n","# print(np.linalg.norm(v1 - v2)) \n","# print(np.linalg.norm(v1 - v3))\n","# print(np.linalg.norm(v1 - v4))\n","# print()\n","\n","# print(np.dot(v1, v)/(np.linalg.norm(v1)*np.linalg.norm(v)))  # normal inference, turns tokenized, lowercase paragraph into 128-vector\n","# print(np.dot(v1, v2)/(np.linalg.norm(v1)*np.linalg.norm(v2)))\n","# print(np.dot(v1, v3)/(np.linalg.norm(v1)*np.linalg.norm(v3)))\n","# print(np.dot(v1, v4)/(np.linalg.norm(v1)*np.linalg.norm(v4)))\n","\n","# print()\n","# print(doc2vec_model.similarity_unseen_docs(test, test4))\n","\n","# # print(doc2vec_model.dv['2'])  # dictionary where each paragraph embedding has a numbered id"],"id":"E12J-l2eXiM-"},{"cell_type":"code","execution_count":null,"metadata":{"id":"1byrFPm5do8S"},"outputs":[],"source":["device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"],"id":"1byrFPm5do8S"},{"cell_type":"markdown","metadata":{"id":"PDWF2apsjZT1"},"source":["##### Preparing LCA loss evaluation function + tools for trees (please run!)"],"id":"PDWF2apsjZT1"},{"cell_type":"code","execution_count":null,"metadata":{"id":"IBXXXBS4jjcT"},"outputs":[],"source":["# tree-related helper functions\n","\n","# iterate over a tree rooted at node in preorder traversal\n","def preorder(node):\n","    if len(node.children) == 0:\n","        yield node\n","    for ch in node.children:\n","        yield from preorder(ch)\n","\n","# only prints leaves, i.e. text representations of paragraph\n","# note: depends on accurate text, level population\n","# text should be indices\n","def print_tree(curNode):\n","    if curNode.level == -1:\n","        print(curNode.text, end='')\n","        return\n","    print('[', end='')\n","    for idx, child in enumerate(curNode.children):\n","        print_tree(child)\n","        if idx < len(curNode.children) - 1:\n","            print(', ', end='')\n","    print(']', end='')\n","    if curNode.level == 0:\n","        print() # final print after entire tree is printed\n","\n","# text should be snippets\n","def print_snippet_tree(curNode, indent='  '):\n","    if curNode.level == -1:\n","        print(indent + curNode.text, end='')\n","        return\n","    print(indent+'[heading]')\n","    for idx, child in enumerate(curNode.children):\n","        print_snippet_tree(child, indent+'  ')\n","        if idx < len(curNode.children) - 1:\n","            print()\n","    if curNode.level == 0:\n","        print() # final print after entire tree is printed\n","\n","def clone_tree(root):\n","    root_copy = Node(root.text, root.level)\n","    for ch in root.children:\n","        root_copy.insertChild(clone_tree(ch))\n","        root_copy.children[-1].linkParent(root_copy)\n","    return root_copy\n","\n","# return indexified tree with text as paragraphs to text as indices of paragraphs for more concise printing\n","def indexified_tree(root):\n","    root_copy = clone_tree(root)\n","    for idx, node in enumerate(preorder(root_copy)):\n","        node.text = idx\n","    return root_copy\n","\n","# return indexified tree with text as paragraphs to text as indices of paragraphs for more concise printing\n","def textified_tree(root, paras):\n","    root_copy = clone_tree(root)\n","    for idx, node in enumerate(preorder(root_copy)):\n","        node.text = paras[idx][:40] + '...'\n","    return root_copy\n","\n","# print_tree(roots[0])\n","# print_tree(train_y[0].root)"],"id":"IBXXXBS4jjcT"},{"cell_type":"code","execution_count":null,"metadata":{"id":"z9hZqeHXjef7"},"outputs":[],"source":["# lca-related helper functions and lca loss\n","# note: assumed indexified trees\n","def trace_helper(node, i, trace):\n","    if node.text == i:\n","        return True\n","    for idx, ch in enumerate(node.children):\n","        if trace_helper(ch, i, trace):\n","            trace.append(idx)\n","            return True\n","    return False\n","\n","def get_trace(root, i):\n","    trace = []\n","    trace_helper(root, i, trace)\n","    trace.reverse()\n","    return trace\n","\n","def compute_lca_dist(root, i, j):\n","    trace_i = get_trace(root, i)\n","    trace_j = get_trace(root, j)\n","    # print(trace_i)\n","    # print(trace_j)\n","    for idx in range(min(len(trace_i), len(trace_j))):\n","        if trace_i[idx] != trace_j[idx]:\n","            return len(trace_i) + len(trace_j) - 2 * idx\n","    return len(trace_i) + len(trace_j)\n","\n","def lca_loss(root1, root2, num_paras):\n","    loss = 0\n","    for i in range(2, num_paras+1): # 1-indexed from indexify\n","        j = i-1\n","        dist1 = compute_lca_dist(root1, i, j)\n","        dist2 = compute_lca_dist(root2, i, j)\n","        # print(i, j, dist1, dist2)\n","        loss += (dist1 - dist2) * (dist1 - dist2)\n","    if num_paras == 1:\n","        return loss\n","    return loss / (num_paras - 1)\n","\n","# def lca_loss(root1, root2, num_paras):\n","#     loss = 0\n","#     for i in range(1, num_paras+1): # 1-indexed from indexify\n","#         for j in range(i+1, num_paras+1):\n","#             dist1 = compute_lca_dist(root1, i, j)\n","#             dist2 = compute_lca_dist(root2, i, j)\n","#             # print(i, j, dist1, dist2)\n","#             loss += (dist1 - dist2) * (dist1 - dist2)\n","#     if num_paras == 1:\n","#         return loss\n","#     return loss / num_paras / (num_paras - 1) * 2\n","\n","def batch_lca_loss(roots1, roots2, num_paras):\n","    tt = 0\n","    for root1, root2, num in zip(roots1, roots2, num_paras):\n","        tt += lca_loss(root1, root2, num)\n","    return tt / len(roots1)"],"id":"z9hZqeHXjef7"},{"cell_type":"markdown","metadata":{"id":"X_aNj3_bh9VG"},"source":["##### Model 1: End-to-end -- note this code may be behind the local version on Evan's big boi computer"],"id":"X_aNj3_bh9VG"},{"cell_type":"markdown","metadata":{"id":"2FDvqg_Xi2mR"},"source":["Approach: SimCSE/Doc2Vec + bidirectional LSTM + transformer -> segmentations"],"id":"2FDvqg_Xi2mR"},{"cell_type":"code","execution_count":null,"metadata":{"id":"OatKuhkFCEcQ"},"outputs":[],"source":["class HeaderNet(nn.Module):\n","    def __init__(self, hid_dim=32, n_layers=1, num_heads=4, # CURRENTLY ONLY SUPPROTS N_LAYERS=1\n","                 num_enc_layers=1, num_dec_layers=1, ff_dim=1024, dropout=0.1, output_dim=2*MAX_DEPTH):\n","        super().__init__()\n","\n","        self.hid_dim = hid_dim\n","        self.n_layers = n_layers\n","        self.num_heads = num_heads\n","        self.num_enc_layers = num_enc_layers\n","        self.num_dec_layers = num_dec_layers\n","        self.ff_dim = ff_dim\n","        self.dropout = dropout\n","\n","        self.lstm = nn.LSTM(SIMCSE_DIM,\n","                            hid_dim,\n","                            num_layers=n_layers,\n","                            bidirectional=True,\n","                            batch_first=True)\n","        self.transformer = nn.Transformer(d_model=hid_dim*4, nhead=num_heads, num_encoder_layers=num_enc_layers,\n","                                          num_decoder_layers=num_dec_layers, dim_feedforward=ff_dim, dropout=dropout, batch_first=True)\n","        self.linear = nn.Linear(hid_dim*4, output_dim)\n","\n","    # masks for transformer to account for variable numbers of paragraphs per article\n","    def compute_len_masks(self, batch):\n","        lens = [len(text) for text in batch]\n","        max_num_paras = max(lens)\n","        len_masks = torch.zeros(len(batch), max_num_paras)\n","        for idx, text_len in enumerate(lens):\n","            len_masks[idx, text_len:] = 1\n","        return lens, len_masks.to(self.device)\n","\n","    # compute sentence embeddings from paragraphs in text\n","    def compute_sentence_embeddings(self, batch):\n","        num_para = [len(x) for x in batch]\n","        batch_para = []\n","\n","        # build list of lists of sentence embeddings\n","        # note that num paragraphs and num sentences are both variable\n","        sents_emb = []\n","        for text in batch:\n","            for para in text:\n","                para = re.sub('\\n', '', para)\n","                sents = re.split('[.]|[!]|[?]', para.strip())\n","                with io.capture_output() as captured:\n","                    sents_emb_i = simcse_model.encode(sents, device=self.device, batch_size=len(sents))\n","                sents_emb.append(sents_emb_i)\n","        return sents_emb\n","\n","    # returns a list of slices along the first dim according to a given list of slice lengths\n","    def partition(self, data, lens):\n","        data_list = []\n","        idx = 0\n","        for len_i in lens:\n","            data_list.append(data[idx:idx+len_i])\n","            idx += len_i\n","        return data_list\n","\n","    def forward(self, batch):\n","        # compute len masks\n","        lens, len_masks = self.compute_len_masks(batch)\n","\n","        # # paragraphs -> sentence embeddings\n","        # sents_emb = self.compute_sentence_embeddings(batch)\n","        # sent_lens = [x.shape[0] for x in sents_emb]\n","        # sents_emb = torch.nn.utils.rnn.pad_sequence(sents_emb, batch_first=True).to(device)\n","        # packed_in = torch.nn.utils.rnn.pack_padded_sequence(sents_emb, sent_lens, batch_first=True, enforce_sorted=False)\n","\n","        # # sentence embeddings -> paragraph embeddings\n","        # packed_out, (hidden, cell) = self.lstm(packed_in.to(self.device))\n","        # para_emb = torch.cat((hidden[0], cell[0], hidden[1], cell[1]), dim=1)\n","        # para_list = self.partition(para_emb, lens) # group paragraph embeddings by article\n","        # print(len(para_list))\n","        # print(para_list[0].shape)\n","        # text_emb = torch.nn.utils.rnn.pad_sequence(para_list, batch_first=True).to(device)\n","        \n","        \n","        para_list = []\n","        for article in batch:\n","          para_list.append(torch.stack([torch.tensor(doc2vec_model.infer_vector(word_tokenize(p.lower())), device=device) for p in article], dim=0))\n","        text_emb = torch.nn.utils.rnn.pad_sequence(para_list, batch_first=True).to(device)\n","        \n","        # paragraph embeddings -> outlines\n","        logits = self.transformer(text_emb, text_emb, src_key_padding_mask=len_masks, tgt_key_padding_mask=len_masks)\n","        logits = logits[len_masks == 0]\n","        logits = self.linear(logits)\n","        logit_list = self.partition(logits, lens)\n","        \n","        return logit_list\n","\n","    @property\n","    def device(self) -> torch.device:\n","        \"\"\" Determine which device to place the Tensors upon, CPU or GPU.\n","        \"\"\"\n","        return device\n","    \n","    @staticmethod\n","    def load(model_path: str):\n","        \"\"\" Load the model from a file.\n","        @param model_path (str): path to model\n","        \"\"\"\n","        params = torch.load(model_path, map_location=lambda storage, loc: storage)\n","        args = params['args']\n","        model = HeaderNet(**args)\n","        model.load_state_dict(params['state_dict'])\n","\n","        return model\n","\n","    def save(self, path: str):\n","        \"\"\" Save the model to a file.\n","        @param path (str): path to the model\n","        \"\"\"\n","\n","        params = {\n","            'args': dict(hid_dim=self.hid_dim, n_layers=self.n_layers, num_heads=self.num_heads,\n","                 num_enc_layers=self.num_enc_layers, num_dec_layers=self.num_dec_layers, ff_dim=self.ff_dim, dropout=self.dropout),\n","            'state_dict': self.state_dict()\n","        }\n","\n","        torch.save(params, path)"],"id":"OatKuhkFCEcQ"},{"cell_type":"code","execution_count":null,"metadata":{"id":"_qnZNERGsYn_"},"outputs":[],"source":["# # encode just the depths -- note that this is insufficient to reconstruct the tree\n","# def add_tree_depths(node, depths, cur_depth):\n","#     if node.level == -1: # this is paragraph node, not a heading\n","#         depths.append(cur_depth)\n","#         return\n","#     for child in node.children:\n","#         add_tree_depths(child, depths, cur_depth+1)\n","\n","# def get_depths(trees, one_hot=True):\n","#     depths = []\n","#     for tree in trees:\n","#         depths_i = []\n","#         add_tree_depths(tree.root, depths_i, 0)\n","#         if one_hot:\n","#             depths.append(F.one_hot(torch.tensor(depths_i), num_classes=MAX_DEPTH))\n","#         else:\n","#             depths.append(torch.tensor(depths_i))\n","#     return torch.stack(depths, dim=0)\n","\n","# encode outlines\n","# note: we use 0 as padding symbol\n","def add_tree_outlines(node, outlines, cur_outline):\n","    if node.level == -1: # this is paragraph node, not a heading\n","        outlines.append(torch.clone(cur_outline))\n","        return\n","    for child in node.children:\n","        cur_outline[node.level] += 1\n","        add_tree_outlines(child, outlines, cur_outline)\n","    cur_outline[node.level] = 0\n","\n","def get_outlines(paras, trees):\n","    max_paras = max([len(x) for x in paras])\n","    outlines = []\n","    for tree in trees:\n","        outlines_i = []\n","        add_tree_outlines(tree.root, outlines_i, torch.zeros(MAX_DEPTH))\n","        outlines_i = torch.stack(outlines_i, dim=0).to(device)\n","        outlines.append(outlines_i)\n","    return outlines\n","\n","# encode breaks\n","\n","def add_tree_segs(node, outlines, cur_outline):\n","    if node.level == -1: # this is paragraph node, not a heading\n","        outlines.append(torch.clone(cur_outline))\n","        return\n","    for child in node.children:\n","        if child == node.children[0]: # first entry\n","            cur_outline[START_IDX + node.level] = 1\n","        if child == node.children[-1]:\n","            cur_outline[END_IDX + node.level] = 1\n","        add_tree_segs(child, outlines, cur_outline)\n","        if child == node.children[0]:\n","            cur_outline[START_IDX + node.level] = 0\n","        if child == node.children[-1]:\n","            cur_outline[END_IDX + node.level] = 0\n","    cur_outline[node.level+1] = 0\n","\n","def get_segs(paras, trees):\n","    max_paras = max([len(x) for x in paras])\n","    outlines = []\n","    for tree in trees:\n","        outlines_i = []\n","        add_tree_segs(tree.root, outlines_i, torch.zeros(2*MAX_DEPTH))\n","        outlines_i = torch.stack(outlines_i, dim=0).to(device)\n","        outlines.append(outlines_i)\n","    return outlines"],"id":"_qnZNERGsYn_"},{"cell_type":"code","execution_count":null,"metadata":{"id":"eyhj2RhkGsXl"},"outputs":[],"source":["# test demo\n","# model = HeaderNet()\n","# device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","# print('use device: %s' % device)\n","# model = model.to(device)\n","# y_hat = model(train_X[0:5])\n","# y = get_outlines(train_X[0:5], train_y[0:5])"],"id":"eyhj2RhkGsXl"},{"cell_type":"code","execution_count":null,"metadata":{"id":"QH-fMeW-oydJ"},"outputs":[],"source":["def get_paragraphs_trees(data):\n","    paras = [d['paragraphs'] for d in data]\n","    trees = [d['tree'] for d in data]\n","    return paras, trees\n","\n","def get_split_data(data, train_ratio=0.05, val_ratio=0.001, test_ratio=0.002):\n","    random.shuffle(data)\n","    n_data = len(data)\n","    train_idx = int(train_ratio*n_data)\n","    val_idx = int((train_ratio + val_ratio)*n_data)\n","    test_idx = int((train_ratio + val_ratio + test_ratio)*n_data)\n","    train_X, train_y = get_paragraphs_trees(data[:train_idx])\n","    val_X, val_y = get_paragraphs_trees(data[train_idx:val_idx])\n","    test_X, test_y = get_paragraphs_trees(data[val_idx:test_idx])\n","    return train_X, train_y, val_X, val_y, test_X, test_y"],"id":"QH-fMeW-oydJ"},{"cell_type":"code","execution_count":null,"metadata":{"id":"2RKkK93gqanM"},"outputs":[],"source":["train_X, train_y, val_X, val_y, test_X, test_y = get_split_data(data)"],"id":"2RKkK93gqanM"},{"cell_type":"code","execution_count":null,"metadata":{"id":"YGLH3oYgIUoC"},"outputs":[],"source":["train_reshaped = torch.cat(get_segs(train_X, train_y), dim=0)\n","train_mean = torch.mean(train_reshaped, dim=0)\n","train_std = torch.std(train_reshaped, dim=0)\n","train_std += 1e-6 # deal with div by zero\n","def normalize(segs):\n","    normed_segs = []\n","    for s in segs:\n","        normed_segs.append(torch.div(torch.sub(s, train_mean), train_std))\n","    return normed_segs"],"id":"YGLH3oYgIUoC"},{"cell_type":"code","execution_count":null,"metadata":{"id":"x8J51HNFJFjG"},"outputs":[],"source":["# # testing normalize\n","# segs = get_segs(train_X, train_y)\n","# normed_segs = normalize(get_segs(train_X, train_y))\n","\n","# v_segs = get_segs(val_X, val_y)\n","# v_normed_segs = normalize(get_segs(val_X, val_y))\n","\n","# print(torch.mean(torch.cat(segs),dim=0))\n","# print(torch.mean(torch.cat(normed_segs),dim=0))\n","# print(torch.std(torch.cat(segs),dim=0))\n","# print(torch.std(torch.cat(normed_segs),dim=0))\n","\n","# print(torch.mean(torch.cat(v_segs),dim=0))\n","# print(torch.mean(torch.cat(v_normed_segs),dim=0))\n","# print(torch.std(torch.cat(v_segs),dim=0))\n","# print(torch.std(torch.cat(v_normed_segs),dim=0))"],"id":"x8J51HNFJFjG"},{"cell_type":"code","execution_count":null,"metadata":{"id":"CZZo91Uglvx_"},"outputs":[],"source":["# iterate over batches of data and labels\n","# articles in batch are sorted by descending num paragraphs for efficient packing/LSTM inference\n","def batch_iter(data, labels, batch_size, shuffle=False):\n","    batch_num = math.ceil(len(data) / batch_size)\n","    index_array = list(range(len(data)))\n","\n","    if shuffle:\n","        np.random.shuffle(index_array)\n","\n","    for i in range(batch_num):\n","        indices = index_array[i * batch_size: (i + 1) * batch_size]\n","        indices = sorted(indices, key=lambda idx: len(data[idx]), reverse=True)\n","        batch_data = [data[idx] for idx in indices]\n","        batch_labels = [labels[idx] for idx in indices]\n","\n","        yield batch_data, batch_labels"],"id":"CZZo91Uglvx_"},{"cell_type":"code","execution_count":null,"metadata":{"id":"6zQERFHtdJxK"},"outputs":[],"source":["def outline_loss(y_hat, y, output_format='segmentation'):\n","    tt_loss = torch.tensor([0.0]).to(device)\n","    if output_format == 'segmentation':\n","        weights = [128, 64, 32, 16, 8, 4, 2, 1, 128, 64, 32, 16, 8, 4, 2, 1]\n","    elif output_format == 'outlines':\n","        weights = [128, 64, 32, 16, 8, 4, 2, 1]\n","    for y_hat_i, y_i in zip(y_hat, y):\n","        loss_weights = torch.tensor(weights).to(device).repeat(y_i.shape[0], 1) # exponentially weight higher level headings more\n","        tt_loss += (torch.square(y_hat_i - y_i)).mul(loss_weights).mean()\n","    return tt_loss / len(y)"],"id":"6zQERFHtdJxK"},{"cell_type":"code","execution_count":null,"metadata":{"id":"lwySi2ltkv-1"},"outputs":[],"source":["def train(train_X, train_y, val_X, val_y, lr=0.002, batch_size=32, grad_clip=5.0, lr_decay=0.5,\n","          max_epoch=50, log_every=5, valid_niter=75, max_patience=4, max_num_trial=5, model_path='model.bin'):\n","    model = HeaderNet()\n","    model.train()\n","\n","    # # initialize model parameters\n","    # for p in model.parameters():\n","    #     p.data.uniform_(-0.1, 0.1)\n","\n","    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","    print('use device: %s' % device)\n","\n","    model_parameters = filter(lambda p: p.requires_grad, model.parameters())\n","    print('{} parameters!'.format(sum([np.prod(p.size()) for p in model_parameters])))\n","\n","    model = model.to(device)\n","    optimizer = torch.optim.Adam(model.parameters(), lr)\n","\n","    num_trial = 0\n","    train_iter = patience = cum_loss = report_loss = cum_tgt_words = report_tgt_words = 0\n","    cum_examples = report_examples = epoch = valid_num = 0\n","    hist_valid_scores = []\n","    train_time = begin_time = time.time()\n","    print('begin Maximum Likelihood training')\n","\n","    train_losses = []\n","    val_losses = []\n","\n","    while True:\n","        epoch += 1\n","        batch_num = math.ceil(len(train_X) / batch_size)\n","        current_iter = 0\n","        for examples, labels in batch_iter(train_X, train_y, batch_size=batch_size, shuffle=True):\n","            model.train()\n","            current_iter += 1\n","            train_iter += 1\n","\n","            optimizer.zero_grad()\n","            batch_size = len(examples)\n","            train_loss = outline_loss(model(examples), get_segs(examples, labels))\n","            train_loss.backward()\n","\n","            # clip gradient\n","            torch.nn.utils.clip_grad_norm_(model.parameters(), grad_clip)\n","\n","            optimizer.step()\n","\n","            report_loss += train_loss\n","            cum_loss += train_loss\n","            report_examples += batch_size\n","            cum_examples += batch_size\n","\n","            if train_iter % log_every == 0:\n","                print('epoch %d (%d / %d), iter %d, avg train loss %.2f, '\n","                      'cum examples %d, time elapsed %.2f sec' %\n","                      (epoch, current_iter, batch_num, train_iter,\n","                       report_loss / report_examples,\n","                       cum_examples,\n","                       time.time() - begin_time))\n","\n","                train_time = time.time()\n","                report_loss = report_examples = 0.\n","\n","            # perform validation\n","            if train_iter % valid_niter == 0:\n","                model.eval()\n","                with torch.no_grad():\n","                    print('epoch %d, iter %d, cum loss %.2f, cum examples %d' % (epoch, train_iter,\n","                            cum_loss / cum_examples,\n","                            cum_examples))\n","                    train_losses.append(cum_loss / cum_examples)\n","                    cum_loss = cum_examples = 0.\n","\n","                    print('begin validation ...')\n","\n","                    val_cum_loss = 0\n","                    val_cum_examples = 0\n","\n","                    count = 0\n","                    NUM_BATCHES = 16  # number of batches to validate over each time\n","                    for e, l in batch_iter(val_X, val_y, batch_size, shuffle=True):\n","                        if count >= NUM_BATCHES:\n","                            break\n","                        batch_size = len(e)\n","                        val_loss = outline_loss(model(e), get_segs(e, l))\n","                        val_cum_loss += val_loss\n","                        val_cum_examples += batch_size\n","                        count += 1\n","\n","                    val_losses.append(val_cum_loss / val_cum_examples)\n","                    valid_metric = -val_cum_loss / val_cum_examples # metric for evaluating whether model is improving on val data\n","\n","                    print('validation: iter %d, val loss %f' % (train_iter, val_loss))\n","\n","                    is_better = len(hist_valid_scores) == 0 or valid_metric > max(hist_valid_scores)\n","                    hist_valid_scores.append(valid_metric)\n","\n","                    if is_better:\n","                        patience = 0\n","                        print('epoch %d, iter %d: save currently the best model to [%s]' %\n","                                (epoch, train_iter, model_path))\n","                        model.save(model_path)\n","                        torch.save(optimizer.state_dict(), model_path + '.optim')\n","                        np.save('train.npy', np.array(train_losses))\n","                        np.save('val.npy', np.array(val_losses))\n","                    elif patience < max_patience:\n","                        patience += 1\n","                        print('hit patience %d' % patience)\n","\n","                        if patience == max_patience:\n","                            num_trial += 1\n","                            print('hit #%d trial' % num_trial)\n","                            if num_trial == max_num_trial:\n","                                print('early stop!')\n","                                exit(0)\n","\n","                            # decay lr, and restore from previously best checkpoint\n","                            lr = optimizer.param_groups[0]['lr'] * lr_decay\n","                            print('load previously best model and decay learning rate to %f' % lr)\n","\n","                            # load model\n","                            params = torch.load(model_path, map_location=lambda storage, loc: storage)\n","                            model.load_state_dict(params['state_dict'])\n","                            model = model.to(device)\n","                            train_losses = list(np.load('train.npy'))\n","                            val_losses = list(np.load('val.npy'))\n","\n","                            print('restore parameters of the optimizers')\n","                            optimizer.load_state_dict(torch.load(model_path + '.optim'))\n","\n","                            # set new lr\n","                            for param_group in optimizer.param_groups:\n","                                param_group['lr'] = lr\n","\n","                            # reset patience\n","                            patience = 0\n","\n","        if epoch == max_epoch:\n","            print('reached maximum number of epochs!')\n","            break"],"id":"lwySi2ltkv-1"},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":351},"executionInfo":{"elapsed":259,"status":"error","timestamp":1650486441294,"user":{"displayName":"Michael Tang","userId":"18009171711496870090"},"user_tz":240},"id":"1PVB2pZ9k2it","outputId":"79071b91-e996-4e97-e72b-05e711afb1db"},"outputs":[{"name":"stdout","output_type":"stream","text":["use device: cuda:0\n","begin Maximum Likelihood training\n"]},{"ename":"RuntimeError","evalue":"ignored","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-66-c55977804641>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-65-d8ab1565b8d6>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(train_X, train_y, val_X, val_y, lr, batch_size, grad_clip, lr_decay, max_epoch, log_every, valid_niter, patience, max_num_trial, model_path)\u001b[0m\n\u001b[1;32m     35\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m             \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexamples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m             \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutline_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexamples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_segs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexamples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m             \u001b[0mtrain_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-63-e64700f87290>\u001b[0m in \u001b[0;36moutline_loss\u001b[0;34m(y_hat, y, output_format)\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mweights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0my_hat_i\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_i\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_hat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0mloss_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_i\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# exponentially weight higher level headings more\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0mtt_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msquare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_hat_i\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0my_i\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtt_loss\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: Could not infer dtype of NoneType"]}],"source":["train(train_X, train_y, val_X, val_y)"],"id":"1PVB2pZ9k2it"},{"cell_type":"code","execution_count":null,"metadata":{"id":"RkmXINGAoG2B"},"outputs":[],"source":["# print(data[0]['tree'].depth)\n","# print(data[0]['title'])\n","# get_outlines([data[0]['paragraphs']], [data[0]['tree']])"],"id":"RkmXINGAoG2B"},{"cell_type":"markdown","metadata":{"id":"HpclBBYffxaL"},"source":["##### Model 2: Greedy decoding + LCA loss"],"id":"HpclBBYffxaL"},{"cell_type":"code","execution_count":null,"metadata":{"id":"MgFl1lNDWKmv"},"outputs":[],"source":["class GreedyDecoder:\n","    def __init__(self, thresholds, similarity, encode):\n","        self.thresholds = thresholds\n","        self.similarity = similarity\n","        self.encode = encode\n","    \n","    # add level and parent info to a tree rooted at node\n","    def update_levels_parents(self, node, depth):\n","        # print(node.text)\n","        if len(node.children) == 0: # leaf paragraph node\n","            node.level = -1\n","            return\n","        node.level = depth\n","        for ch in node.children:\n","            ch.linkParent(node)\n","            self.update_levels_parents(ch, depth+1)\n","\n","    # decodes and returns tree rooted at node\n","    def encode_decode(self, paragraphs):\n","        embs = []\n","        for para in paragraphs:\n","            embs.append(self.encode(para))\n","        return self.decode(embs)\n","    \n","    # decodes and returns tree rooted at node, with text fields populated, e.g. for printing the tree\n","    def encode_decode_with_text(self, X, indexify=True):\n","        root = self.encode_decode(X)\n","        for idx, leaf in enumerate(preorder(root)):\n","            if indexify:\n","                leaf.text = idx\n","            else:\n","                leaf.text = X[idx]\n","        return root\n","    \n","    # here X and y are lists\n","    def batch_encode_decode_with_text(self, X):\n","        roots = []\n","        for X_i in X:\n","            roots.append(self.encode_decode_with_text(X_i))\n","        return roots\n","\n","    # bottom up decoding: for each depth, join paragraphs whose pairwise similarity reaches the threshold\n","    # and represent them collectively by the mean of their embeddings\n","    def decode(self, embs):\n","        if len(embs) == 0:\n","            return Node('', 0) # should never happen\n","        roots = []\n","        for i in range(len(embs)):\n","            roots.append(Node(i, -1))\n","        dim = embs[0].shape[0]\n","        for depth in range(MAX_DEPTH-1): # in last layer, everything must be joined together\n","            next_idxs = [[0]]\n","            for i in range(1, len(embs)):\n","                if self.similarity(embs[i-1], embs[i]) >= self.thresholds[depth]:\n","                    next_idxs[-1].append(i)\n","                else:\n","                    next_idxs.append([i])\n","\n","            # print(next_idxs)\n","            # for root in roots:\n","            #     print_tree(root)\n","\n","            # update roots and embs\n","            next_roots = []\n","            next_embs = []\n","            for comp in next_idxs:\n","                # don't add trivial (1 -> 1) edges\n","                if len(comp) == 1:\n","                    next_roots.append(roots[comp[0]])\n","                    next_embs.append(embs[comp[0]])\n","                    continue\n","\n","                next_roots.append(Node('', -2)) # meaningless params since we only need tree structure\n","                next_embs.append(torch.zeros(dim))\n","                for idx in comp:\n","                    next_roots[-1].insertChild(roots[idx])\n","                    next_embs[-1] += embs[idx]\n","                next_embs[-1] /= len(comp)\n","            roots = next_roots\n","            embs = next_embs\n","        \n","        # join everything together in the last layer\n","        root = Node('', 0)\n","        for node in roots:\n","            root.insertChild(node)\n","\n","        # update parents and levels, then return\n","        self.update_levels_parents(root, 0)\n","        return root"],"id":"MgFl1lNDWKmv"},{"cell_type":"code","execution_count":null,"metadata":{"id":"S0Fpz1pEKcc3"},"outputs":[],"source":["# y = indexified_tree(train_y[0].root)\n","# print_tree(y)\n","# compute_lca_dist(y, 2, 21)\n","# compute_lca_dist(y, y_hat, len(train_X[0]))\n","\n","# greedy = GreedyDecoder([2,3,2,5,5,5,10,10], similarity=doc2vec_sim, encode=doc2vec_enc)\n","# roots = greedy.batch_encode_decode_with_text([train_X[0]], [train_y[0]])"],"id":"S0Fpz1pEKcc3"},{"cell_type":"code","execution_count":null,"metadata":{"id":"rWo1Yua4hCjk"},"outputs":[],"source":["def doc2vec_sim(v1, v2):\n","    return torch.dot(v1, v2) / torch.norm(torch.sub(v1, v2))\n","def doc2vec_enc(v):\n","    return torch.tensor(doc2vec_model.infer_vector(word_tokenize(v)))\n","\n","def simcse_enc(v):\n","    para = re.sub('\\n', '', v)\n","    sents = re.split('[.]|[!]|[?]', para.strip())\n","    with io.capture_output() as captured:\n","        vecs = simcse_model.encode(sents, device=device, batch_size=len(sents))\n","    return torch.mean(vecs, dim=0)"],"id":"rWo1Yua4hCjk"},{"cell_type":"code","execution_count":null,"metadata":{"id":"njWi7UimNnjJ"},"outputs":[],"source":["def evaluate_thresholds(X, y, thresholds, similarity=doc2vec_sim, encode=doc2vec_enc):\n","    greedy = GreedyDecoder(thresholds, similarity=similarity, encode=encode)\n","    y_hat = greedy.batch_encode_decode_with_text(X)\n","    y = [indexified_tree(y_i.root) for y_i in y]\n","    lens = [len(x) for x in X]\n","    return batch_lca_loss(y, y_hat, lens)\n","    # print('Actual:')\n","    # print_tree(y_hat[0])\n","    # print('Predicted:')\n","    # print_tree(y[0])\n","\n","def random_search(X, y, n_tries=50, min_num=[0]*8, max_num=[3]*8, similarity=doc2vec_sim, encode=doc2vec_enc):\n","    results = []\n","    for i in range(n_tries):\n","        print('try #' + str(i))\n","        thresholds = []\n","        for j in range(8):\n","            thresholds.append(random.uniform(min_num[j],max_num[j]))\n","        # print('thresholds:', thresholds)\n","        loss = evaluate_thresholds(X, y, thresholds, similarity=similarity, encode=encode)\n","        results.append({'loss':loss, 'thresholds':thresholds})\n","    \n","    # print sorted version by each index\n","    print('printing sorted by component...')\n","    for i in range(8):\n","        print('component', i)\n","        results_sorted = sorted(results, key=lambda x: x['thresholds'][i])\n","        for result in results_sorted:\n","            thresh =  [\"{0:0.5f}\".format(i) for i in result['thresholds']]\n","            print(result['loss'], '\\t', thresh)\n","        print()"],"id":"njWi7UimNnjJ"},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":185},"executionInfo":{"elapsed":1833,"status":"error","timestamp":1651532789899,"user":{"displayName":"Michael Tang","userId":"18009171711496870090"},"user_tz":240},"id":"EP42xnCssegT","outputId":"3f5c883e-b645-439c-c49d-dfed94cc2767"},"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-27-c3b762d074fa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mrandom_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_X\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m40\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m40\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_tries\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdoc2vec_enc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_num\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_num\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'train_X' is not defined"]}],"source":["random_search(train_X[20:40], train_y[20:40], n_tries=10, encode=doc2vec_enc, min_num=[0,0,0,0,0,0,0,0], max_num=[3,3,3,3,3,3,3,3])"],"id":"EP42xnCssegT"},{"cell_type":"code","execution_count":null,"metadata":{"id":"5cUSNy2ATU6C"},"outputs":[],"source":["def add_tree_breaks(node, breaks, cur_breaks, depths, depth):\n","    if node.level == -1: # this is paragraph node, not a heading\n","        depths.append(depth)\n","        breaks.append(cur_breaks)\n","        return\n","    for child in node.children:\n","        if child == node.children[0]: # first entry\n","            cur_breaks += 1\n","            depth = node.level\n","        if child == node.children[-1]:\n","            cur_breaks = 0\n","            depth = 0\n","        add_tree_breaks(child, breaks, cur_breaks, depths, depth)\n","        if child == node.children[0]:\n","            cur_breaks = 0\n","            depth = 0\n","        if child == node.children[-1]:\n","            cur_breaks = 0\n","            depth = 0\n","    cur_breaks = 0\n","\n","def get_breaks(paras, trees):\n","    max_paras = max([len(x) for x in paras])\n","    breaks = []\n","    depths = []\n","    for tree in trees:\n","        breaks_i = []\n","        depths_i = []\n","        add_tree_breaks(tree.root, breaks_i, 0, depths_i, 0)\n","        breaks_i = torch.tensor(breaks_i)\n","        depths_i[0] += 1\n","        depths_i = torch.tensor(depths_i)\n","        breaks.append(breaks_i)\n","        depths.append(depths_i)\n","    return breaks, depths\n","\n","def convert_dataset(dataset, window_size):\n","  breaks, depths = get_breaks([d['paragraphs'] for d in dataset], [d['tree'] for d in dataset])\n","  X = []\n","  D = []\n","  y = []\n","  for i in tqdm(range(len(dataset))):  # for article\n","      # print('{}'.format(100 * i / len(dataset)))\n","      article = dataset[i]['paragraphs']\n","      for p in range(1, len(article)):  # for para in article (excluding first, since its clearly always a break)\n","          depth = depths[i][p]\n","          isBreak = breaks[i][p]\n","          for b in range(1, depth + 1):  # for depths <= depth of para\n","              context = []\n","              for j in range(p - window_size, p + window_size + 1):  # for para in context\n","                  if j < 0 or j >= len(article):\n","                      context.append(None)\n","                  else:\n","                      context.append(article[j])\n","              X.append(context)\n","              D.append(np.array([b]))\n","              val = 1 if b > depth - isBreak else 0  # 1 if target para is first after break at depth b\n","              y.append(np.array([val]))\n","          if depth == 0:\n","              for b in range(1, 8):  # MAX_DEPTH is 8\n","                  context = []\n","                  for j in range(p - window_size, p + window_size + 1):  # for para in context\n","                      if j < 0 or j >= len(article):\n","                        context.append(None)\n","                      else:\n","                        context.append(article[j])\n","                  X.append(context)\n","                  D.append(np.array([0]))\n","                  y.append(np.array([0]))\n","  return X, torch.tensor(np.stack(D, axis=0)), torch.tensor(np.stack(y, axis=0))\n","\n","def get_split_data(data, window_size, train_ratio=0.8, val_ratio=0.0001, test_ratio=0.0001):\n","    random.shuffle(data)\n","    n_data = len(data)\n","    train_idx = int(train_ratio * n_data)\n","    val_idx = int((train_ratio + val_ratio) * n_data)\n","    test_idx = int((train_ratio + val_ratio + test_ratio) * n_data)\n","    print('getting training data')\n","    train_data = convert_dataset(data[:train_idx], window_size=window_size)\n","    print('getting val data')\n","    val_data = convert_dataset(data[train_idx:val_idx], window_size=window_size)\n","    print('getting test data')\n","    test_data = convert_dataset(data[val_idx:test_idx], window_size=window_size)\n","    return train_data, val_data, test_data\n","\n","# iterate over batches of data and labels\n","def batch_iter(data, batch_size, shuffle=False):\n","    X, D, y = data\n","    batch_num = math.ceil(len(X) / batch_size)\n","    index_array = list(range(len(X)))\n","\n","    if shuffle:\n","        np.random.shuffle(index_array)\n","\n","    for i in range(batch_num):\n","        indices = index_array[i * batch_size: (i + 1) * batch_size]\n","        batch_data_X = [X[idx] for idx in indices]\n","        batch_data_D = D[indices]\n","        batch_data_y = y[indices]\n","\n","        yield batch_data_X, batch_data_D, batch_data_y\n","\n","# MODULES FOR EMBEDDING 3 DIFFERENT WAYS: DOC2VEC, PROJECTED SIMCSE, PROJECTED FASTTEXT\n","# each one takes a batch of lists of paragraphs, outputs a batch of concatenated paragraph embeddings\n","# forward pass input: batch (len B) of list of paragraphs (len 2 * window_size + 1), each para variable length\n","# forward pass output: tensor of size B x ((2 * window_size + 1) * emb_dim)\n","class Doc2VecEmbedding(nn.Module):\n","  def __init__(self, window_size, emb_dim): \n","    super().__init__()\n","    self.emb_dim = emb_dim\n","    self.doc2vec = Doc2Vec.load(\"models/{}_d2v.model\".format(emb_dim))\n","\n","  def forward(self, x):\n","    with torch.no_grad():\n","      batch = []\n","      for b in x:\n","        paras = []\n","        for p in b:\n","          paras.append(self.doc2vec.infer_vector(word_tokenize(p.lower())) if p is not None else np.zeros(shape=(self.emb_dim)))\n","        batch.append(np.concatenate(paras, axis=0))\n","      return torch.tensor(np.stack(batch, axis=0)).to(device)\n","\n","class SimCSEEmbedding(nn.Module):\n","  def __init__(self, window_size, emb_dim, dropout): \n","    super().__init__()\n","    self.window_size = window_size\n","    self.emb_dim = emb_dim\n","    self.simcse = SimCSE(\"princeton-nlp/sup-simcse-bert-base-uncased\")\n","    self.SIMCSE_DIM = 768 # dim of simcse sentence embeddings\n","    self.lstm = nn.LSTM(input_size=self.SIMCSE_DIM,\n","                        hidden_size=int(emb_dim / 4),\n","                        num_layers=1,\n","                        bidirectional=True,\n","                        batch_first=True, \n","                        dropout=0.0).to(device)\n","\n","  def forward(self, x):\n","    B = len(x)  # batch size\n","    batch = []\n","    with torch.no_grad():\n","      for b in x:\n","        for p in b:\n","          if p is not None:\n","            p = re.sub('\\n', '', p)\n","            sents = re.split('[.]|[!]|[?]', p.strip())\n","            with io.capture_output() as captured:\n","                sents_emb = self.simcse.encode(sents, device=device, batch_size=len(sents), max_length=128)  # a tensor of len(sents) x SIMCSE_DIM\n","            batch.append(sents_emb)\n","          else:\n","            batch.append(torch.zeros((1, self.SIMCSE_DIM), device=device))\n","      batch_emb = torch.nn.utils.rnn.pad_sequence(batch, batch_first=True).to(device)\n","      packed_in = torch.nn.utils.rnn.pack_padded_sequence(batch_emb, torch.tensor([a.shape[0] for a in batch_emb]), batch_first=True, enforce_sorted=False)\n","\n","    _, (hidden, cell) = self.lstm(packed_in.to(device))\n","    para_embs = torch.cat((hidden[0], cell[0], hidden[1], cell[1]), dim=1)        \n","      \n","    return para_embs.reshape(B, (2 * self.window_size + 1) * self.emb_dim)\n","\n","\n","#### HERE\n","class FastTextEmbedding(nn.Module):\n","  def __init__(self, window_size, emb_dim, dropout): \n","    super().__init__()\n","    self.window_size = window_size\n","    self.emb_dim = emb_dim\n","    self.fasttext = FastText.load_fasttext_format('models/fast-text-300.bin')\n","    self.FASTTEXT_DIM = 300 # dim of fasttext word embeddings\n","    self.lstm = nn.LSTM(input_size=self.FASTTEXT_DIM,\n","                        hidden_size=int(emb_dim / 4),\n","                        num_layers=1,\n","                        bidirectional=True,\n","                        batch_first=True, \n","                        dropout=0.0).to(device)\n","\n","  def forward(self, x):\n","    B = len(x)  # batch size\n","    batch = []\n","    with torch.no_grad():\n","      for b in x:\n","        for p in b:\n","          if p is not None:\n","            p = re.sub('\\n', '', p)\n","            words = re.sub(\"[^\\s\\w]\", \"\", p.strip()).split(' ')\n","            words = list(filter(None, words))\n","            words_emb = torch.stack([torch.tensor(self.fasttext[word]) for word in words]).to(device)  # a tensor of len(words) x FASTTEXT_DIM\n","            batch.append(words_emb)\n","          else:\n","            batch.append(torch.zeros((1, self.FASTTEXT_DIM), device=device))\n","      batch_emb = torch.nn.utils.rnn.pad_sequence(batch, batch_first=True).to(device)\n","      packed_in = torch.nn.utils.rnn.pack_padded_sequence(batch_emb, torch.tensor([a.shape[0] for a in batch_emb]), batch_first=True, enforce_sorted=False)\n","\n","    _, (hidden, cell) = self.lstm(packed_in.to(device))\n","    para_embs = torch.cat((hidden[0], cell[0], hidden[1], cell[1]), dim=1)        \n","      \n","    return para_embs.reshape(B, (2 * self.window_size + 1) * self.emb_dim)\n","\n","class MLP(nn.Module):\n","  def __init__(self, layer_dims, window_size, emb_dim, emb_method, dropout=0.1):\n","        super().__init__()\n","        self.window_size = window_size\n","        self.emb_dim = emb_dim # dimension of each paragraph embedding\n","        if emb_method == 'doc2vec':\n","          self.emb = Doc2VecEmbedding(window_size, emb_dim)\n","        elif emb_method == 'simcse':\n","          self.emb = SimCSEEmbedding(window_size, emb_dim, dropout=dropout)\n","        elif emb_method == 'fasttext':\n","          self.emb = FastTextEmbedding(window_size, emb_dim, dropout=dropout)\n","        else:\n","          raise NotImplementedError()\n","\n","        in_feats = (2 * window_size + 1) * self.emb_dim\n","        self.layers = []\n","        for dim in layer_dims:\n","          self.layers.append(nn.Linear(in_features=in_feats + 1, out_features=dim))\n","          in_feats = dim\n","        self.layers.append(nn.Linear(in_features=in_feats + 1, out_features=1))\n","        self.layers = nn.ModuleList(self.layers)\n","        self.dropout = nn.Dropout(dropout)\n","\n","  def forward(self, x, d):\n","      '''\n","      x is a batch (list) of windows (list) of paragraphs, which are strings\n","      d is the depths for the whole batch (tensor)\n","      '''\n","      B = len(x)\n","      x = self.emb(x).float()  # x is a (B x (2W + 1) x E) tensor\n","      x = x.reshape(B, (2 * self.window_size + 1) * self.emb_dim)\n","      for layer in self.layers[:-1]:\n","        x = F.relu(layer(torch.cat((x, d), dim=1)))\n","      x = self.dropout(x)\n","      x = torch.sigmoid(self.layers[-1](torch.cat((x, d), dim=1)))\n","      return x\n","\n","  def recursive_outline(self, subarticle, node):\n","    if len(subarticle) == 1:\n","        new = Node(subarticle[0], -1)\n","        new.linkParent(node)\n","        node.insertChild(new)\n","        return\n","    outs = [False]\n","    for p in range(1, len(subarticle)):\n","        context = []\n","        for j in range(p - self.window_size, p + self.window_size + 1):\n","            if j < 0 or j >= len(subarticle):\n","                context.append(None)\n","            else:\n","                context.append(subarticle[j])\n","        X = [context]\n","        D = torch.tensor([node.level + 1]).to(device).unsqueeze(dim=0)\n","        out = self.forward(X, D).squeeze()\n","        outs.append(out.cpu().item() > 0.97)\n","    prev = 0\n","    flag = True\n","    for o in range(len(outs)):\n","        if outs[o]:\n","            new = Node('', node.level + 1)\n","            new.linkParent(node)\n","            node.insertChild(new)\n","            self.recursive_outline(subarticle[prev:o], new)\n","            prev = o\n","            flag = False\n","    if flag:\n","      for p in range(len(subarticle)):\n","        new = Node(subarticle[p], -1)\n","        new.linkParent(node)\n","        node.insertChild(new)\n","\n","        # else:\n","        #     new = Node(subarticle[o], -1)\n","        #     new.linkParent(node)\n","        #     node.insertChild(new)\n","    else:\n","       new = Node('', node.level + 1)\n","       new.linkParent(node)\n","       node.insertChild(new)\n","       self.recursive_outline(subarticle[prev:], new)\n","    return\n","\n","  def outline(self, article, wordy=False):\n","      self.eval()\n","      root = Node('root', 1)\n","      self.recursive_outline(article, root)\n","      new = Node(article[0], -1)\n","      curr = root\n","      while len(curr.children) > 0 and curr.level != -1:\n","        curr = curr.children[0]\n","      new.linkParent(curr.parent)\n","      curr.parent.insertChild(new)\n","      if len(article) > 1:\n","          new = Node(article[len(article)-1], -1)\n","          curr = root\n","          while len(curr.children) > 0 and curr.level != -1:\n","            curr = curr.children[-1]\n","          new.linkParent(curr.parent)\n","          curr.parent.insertChild(new)\n","\n","      def printNode(curNode):\n","          print(curNode.level, '       ', curNode.text)\n","          if curNode.level == -1:\n","              return\n","\n","          for child in curNode.children:\n","              printNode(child)\n","          return\n","\n","      if wordy:\n","        printNode(root)\n","      return root\n","\n","  def save(self, path: str):\n","      \"\"\" Save the model to a file.\n","      @param path (str): path to the model\n","      \"\"\"\n","\n","      params = {\n","          # 'args': dict(hid_dim=self.hid_dim, n_layers=self.n_layers, num_heads=self.num_heads,\n","          #       num_enc_layers=self.num_enc_layers, num_dec_layers=self.num_dec_layers, ff_dim=self.ff_dim, dropout=self.dropout),\n","          'state_dict': self.state_dict()\n","      }\n","\n","      torch.save(params, path)"],"id":"5cUSNy2ATU6C"},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":40632,"status":"ok","timestamp":1651533606951,"user":{"displayName":"Michael Tang","userId":"18009171711496870090"},"user_tz":240},"id":"ltaPAg3hSu8f","outputId":"36f2b354-b046-4911-c5eb-d9045a096e20"},"outputs":[{"output_type":"stream","name":"stderr","text":["05/02/2022 23:19:26 - INFO - gensim.utils -   loading Doc2Vec object from models/256_d2v.model\n","05/02/2022 23:19:26 - INFO - gensim.utils -   loading dv recursively from models/256_d2v.model.dv.* with mmap=None\n","05/02/2022 23:19:26 - INFO - gensim.utils -   loading vectors from models/256_d2v.model.dv.vectors.npy with mmap=None\n","05/02/2022 23:19:28 - INFO - gensim.utils -   loading wv recursively from models/256_d2v.model.wv.* with mmap=None\n","05/02/2022 23:19:28 - INFO - gensim.utils -   loading vectors from models/256_d2v.model.wv.vectors.npy with mmap=None\n","05/02/2022 23:19:29 - INFO - gensim.utils -   loading syn1neg from models/256_d2v.model.syn1neg.npy with mmap=None\n","05/02/2022 23:19:30 - INFO - gensim.utils -   setting ignored attribute cum_table to None\n","05/02/2022 23:19:33 - INFO - gensim.utils -   Doc2Vec lifecycle event {'fname': 'models/256_d2v.model', 'datetime': '2022-05-02T23:19:33.186971', 'gensim': '4.1.2', 'python': '3.7.13 (default, Apr 24 2022, 01:04:09) \\n[GCC 7.5.0]', 'platform': 'Linux-5.4.188+-x86_64-with-Ubuntu-18.04-bionic', 'event': 'loaded'}\n"]}],"source":["# getting losses from recursive MLP\n","\n","# MODEL SPECS\n","WINDOW_SIZE = 3  # number of neighbors to consider in each direction\n","EMB_DIM = 256  # dim each paragraph becomes, via magic :)\n","EMB_METHOD = 'doc2vec'  # one of 'doc2vec', 'simcse', 'fasttext'\n","MLP_ARCHITECTURE = [1024, 256, 64]  # sizes of hidden layers in MLP\n","\n","model = MLP(layer_dims=MLP_ARCHITECTURE, window_size=WINDOW_SIZE, emb_dim=EMB_DIM, emb_method=EMB_METHOD)\n","\n","# EVAL STUFF\n","params = torch.load('checkpoints/mlp_{}.bin'.format(EMB_METHOD), map_location=lambda storage, loc: storage)\n","model.load_state_dict(params['state_dict'])\n","model = model.to(device)"],"id":"ltaPAg3hSu8f"},{"cell_type":"code","execution_count":null,"metadata":{"id":"uf-FPRECUs9n"},"outputs":[],"source":["X = test_X\n","y = test_y\n","roots = [indexified_tree(model.outline(a)) for a in X]\n","golds = [indexified_tree(a.root) for a in y]\n","lens = [len(a) for a in X]\n","# batch_lca_loss(roots, golds, lens)\n","y_hat = roots\n","y = golds"],"id":"uf-FPRECUs9n"},{"cell_type":"code","source":["batch_lca_loss(roots, golds, lens)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jVauiLjiDXY3","executionInfo":{"status":"ok","timestamp":1651533672756,"user_tz":240,"elapsed":257,"user":{"displayName":"Michael Tang","userId":"18009171711496870090"}},"outputId":"62276995-8308-47ce-8a0f-991eebaa8c8e"},"id":"jVauiLjiDXY3","execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["1.3225866131218016"]},"metadata":{},"execution_count":72}]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4083,"status":"ok","timestamp":1651533022140,"user":{"displayName":"Michael Tang","userId":"18009171711496870090"},"user_tz":240},"id":"kPYJXOv5boxM","outputId":"dc6bb4bb-a4fd-4bb5-ce91-d155aea1310a"},"outputs":[{"output_type":"stream","name":"stdout","text":["1.2354015566147911\n"]}],"source":["thresholds = [1.769, 1.261, 0.007, 2.289, 1.793, 0.590, 3.620, 3.969] # 128 thresholds\n","# thresholds = [1.769, 1.261, 0.007, 2.289, 1.793, 0.590, 3.620, 3.969] # 256 thresholds\n","# thresholds = [1.668, 0.429, 0.810, 2.581, 1.015, 1.205, 1.755, 0.440] # simcse thresholds\n","X = test_X\n","y = test_y\n","\n","greedy = GreedyDecoder(thresholds, similarity=doc2vec_sim, encode=doc2vec_enc)\n","# greedy = GreedyDecoder(thresholds, similarity=doc2vec_sim, encode=simcse_enc)\n","y_hat = greedy.batch_encode_decode_with_text(X)\n","y = [indexified_tree(y_i.root) for y_i in y]\n","lens = [len(x) for x in X]\n","print(batch_lca_loss(y, y_hat, lens))\n","\n","# for i in range(10):\n","#     print(i)\n","#     print('Predicted:')\n","#     print_tree(y_hat[i])\n","#     print('Actual:')\n","#     print_tree(y[i])"],"id":"kPYJXOv5boxM"},{"cell_type":"code","source":["print_tree(y[5])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aCTXahlNCjlB","executionInfo":{"status":"ok","timestamp":1651533681238,"user_tz":240,"elapsed":4,"user":{"displayName":"Michael Tang","userId":"18009171711496870090"}},"outputId":"3bc06b0e-57cd-4242-d593-22757ce399c1"},"id":"aCTXahlNCjlB","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[0, 1, 2, [3, 4, 5], [6, 7, 8, 9, 10], [[11, 12, 13], [14, 15, 16]], [17, 18, 19], [20, 21, 22, [23]], [[24, 25, 26], [27, 28, 29, 30, 31]], [32, 33, 34, 35], [36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61]]\n"]}]},{"cell_type":"code","source":["print_tree(y_hat[5])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XlsZ2WMBCz9X","executionInfo":{"status":"ok","timestamp":1651533682223,"user_tz":240,"elapsed":3,"user":{"displayName":"Michael Tang","userId":"18009171711496870090"}},"outputId":"c4090ef7-c1e9-4e57-9c3b-09e9257c7d71"},"id":"XlsZ2WMBCz9X","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63]"]}]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":18086,"status":"ok","timestamp":1651481821275,"user":{"displayName":"Michael Tang","userId":"18009171711496870090"},"user_tz":240},"id":"KqzMYmxLwtpD","outputId":"94b90283-ee3b-4645-df84-74adf726117b"},"outputs":[{"name":"stdout","output_type":"stream","text":["1.8826851358941468\n"]}],"source":["print(batch_lca_loss(y, y_hat, lens))"],"id":"KqzMYmxLwtpD"},{"cell_type":"code","execution_count":null,"metadata":{"id":"p5Uh2CSQ3bJ2"},"outputs":[],"source":["model_losses = []\n","for len_i, y_i, y_hat_i in zip(lens, y, y_hat):\n","    model_losses.append(lca_loss(y_i, y_hat_i, len_i))"],"id":"p5Uh2CSQ3bJ2"},{"cell_type":"code","execution_count":null,"metadata":{"id":"SWVHchil3ovC","colab":{"base_uri":"https://localhost:8080/","height":17},"executionInfo":{"status":"ok","timestamp":1651533721084,"user_tz":240,"elapsed":1051,"user":{"displayName":"Michael Tang","userId":"18009171711496870090"}},"outputId":"f5e70a36-892a-4c38-c095-385a3ef7bcfb"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["\n","    async function download(id, filename, size) {\n","      if (!google.colab.kernel.accessAllowed) {\n","        return;\n","      }\n","      const div = document.createElement('div');\n","      const label = document.createElement('label');\n","      label.textContent = `Downloading \"${filename}\": `;\n","      div.appendChild(label);\n","      const progress = document.createElement('progress');\n","      progress.max = size;\n","      div.appendChild(progress);\n","      document.body.appendChild(div);\n","\n","      const buffers = [];\n","      let downloaded = 0;\n","\n","      const channel = await google.colab.kernel.comms.open(id);\n","      // Send a message to notify the kernel that we're ready.\n","      channel.send({})\n","\n","      for await (const message of channel.messages) {\n","        // Send a message to notify the kernel that we're ready.\n","        channel.send({})\n","        if (message.buffers) {\n","          for (const buffer of message.buffers) {\n","            buffers.push(buffer);\n","            downloaded += buffer.byteLength;\n","            progress.value = downloaded;\n","          }\n","        }\n","      }\n","      const blob = new Blob(buffers, {type: 'application/binary'});\n","      const a = document.createElement('a');\n","      a.href = window.URL.createObjectURL(blob);\n","      a.download = filename;\n","      div.appendChild(a);\n","      a.click();\n","      div.remove();\n","    }\n","  "]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["download(\"download_a32ad7bb-202d-48b5-a0cb-a0699fe2c67d\", \"mlp_loss.csv\", 819)"]},"metadata":{}}],"source":["import csv\n","from google.colab import files\n","\n","with open(\"mlp_loss.csv\", \"w\") as f:\n","    writer = csv.writer(f)\n","    writer.writerow(model_losses)\n","files.download('mlp_loss.csv')"],"id":"SWVHchil3ovC"},{"cell_type":"markdown","metadata":{"id":"1j2UAawngVgV"},"source":["Here we simulate the degenerate output from the end-to-end model to get LCA loss of that model"],"id":"1j2UAawngVgV"},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1825,"status":"ok","timestamp":1651477975112,"user":{"displayName":"Michael Tang","userId":"18009171711496870090"},"user_tz":240},"id":"z4uUx5hYl0sP","outputId":"553ef939-bbbe-4dd9-fc71-8e9557d442f9"},"outputs":[{"name":"stdout","output_type":"stream","text":["4.731525515214907\n"]}],"source":["bad_node = Node(-1,0)\n","for i in range(100):\n","    bad_node.insertChild(Node(i,-1))\n","\n","# thresholds = [1.769, 1.261, 0.007, 2.289, 1.793, 0.590, 3.620, 3.969]\n","X = val_X\n","y = val_y\n","\n","greedy = GreedyDecoder(thresholds, similarity=doc2vec_sim, encode=doc2vec_enc)\n","y_hat = [bad_node]*len(y)\n","y = [indexified_tree(y_i.root) for y_i in y]\n","lens = [len(x) for x in X]\n","print(batch_lca_loss(y, y_hat, lens))"],"id":"z4uUx5hYl0sP"},{"cell_type":"markdown","metadata":{"id":"rmhSuAZMgbYO"},"source":["We can hard-code to extract specific results here:"],"id":"rmhSuAZMgbYO"},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"elapsed":208,"status":"ok","timestamp":1650535212167,"user":{"displayName":"Michael Tang","userId":"18009171711496870090"},"user_tz":240},"id":"dPaeL9nneQ-c","outputId":"564ef17e-e5a6-41a0-b251-9289dd010c28"},"outputs":[{"data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'M @-@ 331 ( Michigan highway )'"]},"execution_count":347,"metadata":{},"output_type":"execute_result"}],"source":["val_y[10].root.text"],"id":"dPaeL9nneQ-c"},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":130,"status":"ok","timestamp":1650535513374,"user":{"displayName":"Michael Tang","userId":"18009171711496870090"},"user_tz":240},"id":"fjFZlDETfXTI","outputId":"a2b2d9a6-634c-4998-9fee-9e25c2e8c820"},"outputs":[{"name":"stdout","output_type":"stream","text":["  [heading]\n","    [heading]\n","      [heading]\n","        [heading]\n","           Dan Dugan ( born March 20 , 1943 ) is a...\n","           In his youth , Dugan was fascinated by ...\n","           Dugan first recorded sounds in the late...\n","         Daniel W. Dugan was born in Los Angeles...\n","        [heading]\n","           Dugan changed from lighting design to s...\n","           Dugan designed sound for three regional...\n","           When Margrit Mondavi founded the Mondav...\n","      [heading]\n","         Dugan occasionally delivered speeches a...\n","        [heading]\n","           While designing sound for the musical H...\n","           Though the algorithm was good , the ref...\n","           \" I was messing around with logarithmic...\n","         Dugan licensed this more practical syst...\n","        [heading]\n","           In the late 1980s , Dugan developed a g...\n","           Dugan 's original 1974 patent expired i...\n","        [heading]\n","           In September 2006 , Dugan produced the ...\n","           In February 2011 , Dugan demonstrated a...\n","         Dugan made his first sound effects reco...\n","         Dugan and his wife Sharon Perry , the N...\n","         \" There are three potential values in s...\n","         In 2006 , Dugan assisted a group of res...\n","         In 1998 an organization he co @-@ found...\n","         As co @-@ founder and Secretary of PLAN...\n"]}],"source":["print_snippet_tree(textified_tree(y_hat[7], val_X[7]))"],"id":"fjFZlDETfXTI"},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":171,"status":"ok","timestamp":1650535518477,"user":{"displayName":"Michael Tang","userId":"18009171711496870090"},"user_tz":240},"id":"CHzt_3Bug96V","outputId":"197bd189-78ba-4aab-98d7-937f28cd0ad5"},"outputs":[{"name":"stdout","output_type":"stream","text":["  [heading]\n","     Dan Dugan ( born March 20 , 1943 ) is a...\n","     In his youth , Dugan was fascinated by ...\n","     Dugan first recorded sounds in the late...\n","    [heading]\n","       Daniel W. Dugan was born in Los Angeles...\n","    [heading]\n","       Dugan changed from lighting design to s...\n","       Dugan designed sound for three regional...\n","       When Margrit Mondavi founded the Mondav...\n","       Dugan occasionally delivered speeches a...\n","    [heading]\n","       While designing sound for the musical H...\n","       Though the algorithm was good , the ref...\n","       \" I was messing around with logarithmic...\n","       Dugan licensed this more practical syst...\n","       In the late 1980s , Dugan developed a g...\n","       Dugan 's original 1974 patent expired i...\n","       In September 2006 , Dugan produced the ...\n","       In February 2011 , Dugan demonstrated a...\n","    [heading]\n","       Dugan made his first sound effects reco...\n","       Dugan and his wife Sharon Perry , the N...\n","       \" There are three potential values in s...\n","       In 2006 , Dugan assisted a group of res...\n","    [heading]\n","       In 1998 an organization he co @-@ found...\n","       As co @-@ founder and Secretary of PLAN...\n"]}],"source":["print_snippet_tree(textified_tree(y[7], val_X[7]))"],"id":"CHzt_3Bug96V"},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9540,"status":"ok","timestamp":1650530936386,"user":{"displayName":"Michael Tang","userId":"18009171711496870090"},"user_tz":240},"id":"B2KLLiYbO87K","outputId":"2462738e-e520-47c3-d29e-7a7f5587aad3"},"outputs":[{"name":"stdout","output_type":"stream","text":["45.15277996900072\n","Actual:\n","[[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15], [16, 17, 18, 19], 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31]\n","Predicted:\n","[0, 1, [2, 3, 4, 5], [6, 7], [8, 9], [10, 11, 12], [13, 14], [15], [16, [17, 18, 19, 20, 21], [22, 23], [24, 25, 26, 27, 28, 29, 30, 31]]]\n"]}],"source":["evaluate_thresholds(train_X[:100], train_y[:100], [1.3,3,2,2,8,8,8,8])"],"id":"B2KLLiYbO87K"},{"cell_type":"markdown","metadata":{"id":"wStwFp0dgjKJ"},"source":["And here we look at the doc2vec distributions"],"id":"wStwFp0dgjKJ"},{"cell_type":"code","execution_count":null,"metadata":{"id":"WZNawe-4QdLy"},"outputs":[],"source":["# investigate distribution of Doc2Vec distributions\n","def plot_similarity_distribution(similarity=doc2vec_sim, encode=simcse_enc):\n","    sims = []\n","    n = len(train_X[0])\n","    for x in range(n):\n","        for y in range(x+1,n):\n","            # print(doc2vec_enc(train_X[0][x]), doc2vec_enc(train_X[0][y]))\n","            sims.append(similarity(encode(train_X[0][x]), encode(train_X[0][y])))\n","    plt.hist(sims)\n","    plt.xlabel('Similarity')\n","    plt.ylabel('Count')\n","    plt.show()"],"id":"WZNawe-4QdLy"},{"cell_type":"code","execution_count":null,"metadata":{"id":"f7wFwTidrCH4"},"outputs":[],"source":["plot_similarity_distribution()"],"id":"f7wFwTidrCH4"},{"cell_type":"markdown","metadata":{"id":"yc5HGcLzgoFv"},"source":["##### Model 3: Recursive split MLP -- note this code may have a decoding bug"],"id":"yc5HGcLzgoFv"},{"cell_type":"code","execution_count":null,"metadata":{"id":"Lr1puvn7hOmI"},"outputs":[],"source":["WINDOW_SIZE = 2  # WINDOW_SIZE paragraphs on each side of target para are considered\n","DOC2VEC_DIM = 128"],"id":"Lr1puvn7hOmI"},{"cell_type":"code","execution_count":null,"metadata":{"id":"cvpuvYJnhci0"},"outputs":[],"source":["def add_tree_breaks(node, breaks, cur_breaks, depths, depth):\n","    if node.level == -1: # this is paragraph node, not a heading\n","        depths.append(depth)\n","        breaks.append(cur_breaks)\n","        return\n","    for child in node.children:\n","        if child == node.children[0]: # first entry\n","            cur_breaks += 1\n","            depth = node.level\n","        if child == node.children[-1]:\n","            cur_breaks = 0\n","            depth = 0\n","        add_tree_breaks(child, breaks, cur_breaks, depths, depth)\n","        if child == node.children[0]:\n","            cur_breaks = 0\n","            depth = 0\n","        if child == node.children[-1]:\n","            cur_breaks = 0\n","            depth = 0\n","    cur_breaks = 0\n","\n","def get_breaks(paras, trees):\n","    max_paras = max([len(x) for x in paras])\n","    breaks = []\n","    depths = []\n","    for tree in trees:\n","        breaks_i = []\n","        depths_i = []\n","        add_tree_breaks(tree.root, breaks_i, 0, depths_i, 0)\n","        breaks_i = torch.tensor(breaks_i)\n","        depths_i[0] += 1\n","        depths_i = torch.tensor(depths_i)\n","        breaks.append(breaks_i)\n","        depths.append(depths_i)\n","    return breaks, depths\n","\n","def convert_dataset(dataset):\n","  breaks, depths = get_breaks([d['paragraphs'] for d in dataset], [d['tree'] for d in dataset])\n","  X = []\n","  D = []\n","  y = []\n","  for i in range(len(dataset)):  # for article\n","      print('{}'.format(100 * i / len(dataset)))\n","      article = dataset[i]['paragraphs']\n","      for p in range(1, len(article)):  # for para in article (excluding first, since its clearly always a break)\n","          depth = depths[i][p]\n","          isBreak = breaks[i][p]\n","          for b in range(1, depth + 1):  # for depths <= depth of para\n","              context = []\n","              for j in range(p - WINDOW_SIZE, p + WINDOW_SIZE + 1):  # for para in context\n","                  if j < 0 or j >= len(article):\n","                      context.append(np.zeros([DOC2VEC_DIM]))\n","                  else:\n","                      context.append(doc2vec_model.infer_vector(word_tokenize(article[j].lower())))\n","              X.append(np.concatenate(context, axis=0))\n","              D.append(np.array([b]))\n","              val = 1 if b > depth - isBreak else 0  # 1 if target para is first after break at depth b\n","              y.append(np.array([val]))\n","          if depth == 0:\n","              for b in range(1, MAX_DEPTH):\n","                  context = []\n","                  for j in range(p - WINDOW_SIZE, p + WINDOW_SIZE + 1):  # for para in context\n","                      if j < 0 or j >= len(article):\n","                          context.append(np.zeros([DOC2VEC_DIM]))\n","                      else:\n","                          context.append(doc2vec_model.infer_vector(word_tokenize(article[j].lower())))\n","                  X.append(np.concatenate(context, axis=0))\n","                  D.append(np.array([0]))\n","                  y.append(np.array([0]))\n","  return np.stack(X, axis=0), np.stack(D, axis=0), np.stack(y, axis=0)"],"id":"cvpuvYJnhci0"},{"cell_type":"code","execution_count":null,"metadata":{"id":"1Ce1cQI_hjKm"},"outputs":[],"source":["def get_split_data(data, train_ratio=0.0008, val_ratio=0.0001, test_ratio=0.0001):\n","    random.shuffle(data)\n","    n_data = len(data)\n","    train_idx = int(train_ratio * n_data)\n","    val_idx = int((train_ratio + val_ratio) * n_data)\n","    test_idx = int((train_ratio + val_ratio + test_ratio) * n_data)\n","    train_data = convert_dataset(data[:train_idx])\n","    val_data = convert_dataset(data[train_idx:val_idx])\n","    test_data = convert_dataset(data[val_idx:test_idx])\n","    return train_data, val_data, test_data"],"id":"1Ce1cQI_hjKm"},{"cell_type":"code","execution_count":null,"metadata":{"id":"uQIdIQvAheHi"},"outputs":[],"source":["train_data, val_data, test_data = get_split_data(data)"],"id":"uQIdIQvAheHi"},{"cell_type":"code","execution_count":null,"metadata":{"id":"D5oIYe9shkio"},"outputs":[],"source":["# iterate over batches of data and labels\n","# articles in batch are sorted by descending num paragraphs for efficient packing/LSTM inference\n","def batch_iter(data, batch_size, shuffle=False):\n","    batch_num = math.ceil(len(dataX) / batch_size)\n","    index_array = list(range(len(dataX)))\n","\n","    if shuffle:\n","        np.random.shuffle(index_array)\n","\n","    for i in range(batch_num):\n","        indices = index_array[i * batch_size: (i + 1) * batch_size]\n","        batch_data_X = torch.tensor(dataX[indices])\n","        batch_data_D = torch.tensor(dataD[indices])\n","        batch_data_y = torch.tensor(datay[indices])\n","\n","        yield batch_data_X, batch_data_D, batch_data_y"],"id":"D5oIYe9shkio"},{"cell_type":"code","execution_count":null,"metadata":{"id":"K2ayqAuIhqjt"},"outputs":[],"source":["class MLP(nn.Module):\n","  def __init__(self, layer_dims, dropout=0.1):\n","        super().__init__()\n","        in_feats = (2 * WINDOW_SIZE + 1) * DOC2VEC_DIM\n","        self.layers = []\n","        for dim in layer_dims:\n","          self.layers.append(nn.Linear(in_features=in_feats + 1, out_features=dim))\n","          in_feats = dim\n","        self.layers.append(nn.Linear(in_features=in_feats + 1, out_features=1))\n","        self.layers = nn.ModuleList(self.layers)\n","        self.dropout = nn.Dropout(dropout)\n","\n","  def forward(self, x, d):\n","      for layer in self.layers[:-1]:\n","        x = F.relu(layer(torch.cat((x, d), dim=1)))\n","      x = self.dropout(x)\n","      x = torch.sigmoid(self.layers[-1](torch.cat((x, d), dim=1)))\n","      return x\n","\n","  def recursive_outline(self, subarticle, node):\n","    if len(subarticle) == 1:\n","        new = Node(subarticle[0], -1)\n","        new.linkParent(node)\n","        node.insertChild(new)\n","        return\n","    outs = [False]\n","    for p in range(1, len(subarticle)):\n","        context = []\n","        for j in range(p - WINDOW_SIZE, p + WINDOW_SIZE + 1):\n","            if j < 0 or j >= len(subarticle):\n","                context.append(np.zeros([DOC2VEC_DIM]))\n","            else:\n","                context.append(doc2vec_model.infer_vector(word_tokenize(subarticle[j].lower())))\n","        X = torch.tensor(np.concatenate(context, axis=0), device=device, dtype=torch.float32).unsqueeze(dim=0)\n","        D = torch.tensor([node.level + 1]).to(device).unsqueeze(dim=0)\n","        out = self.forward(X, D).squeeze()\n","        outs.append(out.cpu().item() > 0.77)\n","    prev = 0\n","    flag = True\n","    for o in range(len(outs)):\n","        if outs[o]:\n","            new = Node('', node.level + 1)\n","            new.linkParent(node)\n","            node.insertChild(new)\n","            self.recursive_outline(subarticle[prev:o], new)\n","            prev = o\n","            flag = False\n","    if flag:\n","      for p in range(len(subarticle)):\n","        new = Node(subarticle[p], -1)\n","        new.linkParent(node)\n","        node.insertChild(new)\n","\n","        # else:\n","        #     new = Node(subarticle[o], -1)\n","        #     new.linkParent(node)\n","        #     node.insertChild(new)\n","    else:\n","       new = Node('', node.level + 1)\n","       new.linkParent(node)\n","       node.insertChild(new)\n","       self.recursive_outline(subarticle[prev:], new)\n","    return\n","\n","  def outline(self, article, wordy=False):\n","      self.eval()\n","      root = Node('root', 1)\n","      self.recursive_outline(article, root)\n","      new = Node(article[0], -1)\n","      curr = root\n","      while len(curr.children) > 0 and curr.level != -1:\n","        curr = curr.children[0]\n","      new.linkParent(curr.parent)\n","      curr.parent.insertChild(new)\n","      if len(article) > 1:\n","          new = Node(article[len(article)-1], -1)\n","          curr = root\n","          while len(curr.children) > 0 and curr.level != -1:\n","            curr = curr.children[-1]\n","          new.linkParent(curr.parent)\n","          curr.parent.insertChild(new)\n","\n","      def printNode(curNode):\n","          print(curNode.level, '       ', curNode.text)\n","          if curNode.level == -1:\n","              return\n","\n","          for child in curNode.children:\n","              printNode(child)\n","          return\n","\n","      if wordy:\n","        printNode(root)\n","      return root\n","\n","  @staticmethod\n","  def load(model_path: str):\n","      \"\"\" Load the model from a file.\n","      @param model_path (str): path to model\n","      \"\"\"\n","      params = torch.load(model_path, map_location=lambda storage, loc: storage)\n","      # args = params['args']\n","      model = MLP(layer_dims=[1024, 256, 64])\n","      model.load_state_dict(params['state_dict'])\n","\n","      return model\n","\n","  def save(self, path: str):\n","      \"\"\" Save the model to a file.\n","      @param path (str): path to the model\n","      \"\"\"\n","\n","      params = {\n","          # 'args': dict(hid_dim=self.hid_dim, n_layers=self.n_layers, num_heads=self.num_heads,\n","          #       num_enc_layers=self.num_enc_layers, num_dec_layers=self.num_dec_layers, ff_dim=self.ff_dim, dropout=self.dropout),\n","          'state_dict': self.state_dict()\n","      }\n","\n","      torch.save(params, path)"],"id":"K2ayqAuIhqjt"},{"cell_type":"code","execution_count":null,"metadata":{"id":"kFhfncT-hruW"},"outputs":[],"source":["def train(train_data, val_data, lr=0.002, batch_size=1, grad_clip=5.0, lr_decay=0.5,\n","          max_epoch=50, log_every=5, valid_niter=25, max_patience=4, max_num_trial=5, model_path='model.bin'):\n","    model = MLP(layer_dims=[1024, 256, 64])\n","    model.train()\n","\n","    # # initialize model parameters\n","    # for p in model.parameters():\n","    #     p.data.uniform_(-0.1, 0.1)\n","\n","    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","    print('use device: %s' % device)\n","\n","    model_parameters = filter(lambda p: p.requires_grad, model.parameters())\n","    print('{} parameters!'.format(sum([np.prod(p.size()) for p in model_parameters])))\n","\n","    model = model.to(device)\n","    optimizer = torch.optim.Adam(model.parameters(), lr)\n","\n","    num_trial = 0\n","    train_iter = patience = cum_loss = report_loss = cum_tgt_words = report_tgt_words = 0\n","    cum_examples = report_examples = epoch = valid_num = 0\n","    hist_valid_scores = []\n","    train_time = begin_time = time.time()\n","    print('begin Maximum Likelihood training')\n","\n","    train_losses = []\n","    val_losses = []\n","    loss_fn = nn.BCELoss(reduction='sum')\n","\n","    train_X = np.load('train_X.npy', allow_pickle=True)\n","    train_D = np.load('train_D.npy', allow_pickle=True)\n","    train_y = np.load('train_y.npy', allow_pickle=True)\n","    \n","    # train_X, train_D, train_y = train_data\n","    val_X, val_D, val_y = val_data\n","\n","    while True:\n","        epoch += 1\n","        batch_num = math.ceil(len(train_data) / batch_size)\n","        current_iter = 0\n","        for batch in batch_iter(train_data, batch_size=batch_size, shuffle=True):\n","            X, D, y = convert_dataset(batch)\n","            X = X.to(device)\n","            D = D.to(device)\n","            y = y.to(dtype=torch.float32, device=device)\n","\n","            model.train()\n","            current_iter += 1\n","            train_iter += 1\n","\n","            optimizer.zero_grad()\n","            batch_size = len(X)\n","            out = model(X, D)\n","            train_loss = loss_fn(out, y)\n","            train_loss.backward()\n","\n","            # clip gradient\n","            torch.nn.utils.clip_grad_norm_(model.parameters(), grad_clip)\n","\n","            optimizer.step()\n","\n","            report_loss += train_loss.item()\n","            cum_loss += train_loss.item()\n","            report_examples += batch_size\n","            cum_examples += batch_size\n","\n","            if train_iter % log_every == 0:\n","                print('epoch %d (%d / %d), iter %d, avg train loss %f, '\n","                      'cum examples %d, time elapsed %.2f sec' %\n","                      (epoch, current_iter, batch_num, train_iter,\n","                       report_loss / report_examples,\n","                       cum_examples,\n","                       time.time() - begin_time))\n","\n","                train_time = time.time()\n","                report_loss = report_examples = 0.\n","\n","            # perform validation\n","            if train_iter % valid_niter == 0:\n","                model.eval()\n","                with torch.no_grad():\n","                    print('epoch %d, iter %d, cum loss %f, cum examples %d' % (epoch, train_iter,\n","                            cum_loss / cum_examples,\n","                            cum_examples))\n","                    train_losses.append(cum_loss / cum_examples)\n","                    cum_loss = cum_examples = 0.\n","\n","                    print('begin validation ...')\n","\n","                    val_cum_loss = 0.\n","                    val_cum_examples = 0\n","\n","                    count = 0\n","                    NUM_BATCHES = 8  # number of batches to validate over each time\n","                    for batch in batch_iter(val_data, batch_size, shuffle=True):\n","                        if count >= NUM_BATCHES:\n","                            break\n","                        X, D, y = convert_dataset(batch)\n","                        X = X.to(device)\n","                        D = D.to(device)\n","                        y = y.to(dtype=torch.float32, device=device)\n","\n","                        batch_size = len(X)\n","                        out = model(X, D)\n","                        val_loss = loss_fn(out, y)\n","                        val_cum_loss += val_loss.item()\n","                        val_cum_examples += batch_size\n","                        count += 1\n","\n","                    val_losses.append(val_cum_loss / val_cum_examples)\n","                    valid_metric = -val_cum_loss / val_cum_examples # metric for evaluating whether model is improving on val data\n","\n","                    print('validation: iter %d, val loss %f' % (train_iter, val_cum_loss / val_cum_examples))\n","\n","                    is_better = len(hist_valid_scores) == 0 or valid_metric > max(hist_valid_scores)\n","                    hist_valid_scores.append(valid_metric)\n","\n","                    if is_better:\n","                        patience = 0\n","                        print('epoch %d, iter %d: save currently the best model to [%s]' %\n","                                (epoch, train_iter, model_path))\n","                        model.save(model_path)\n","                        torch.save(optimizer.state_dict(), model_path + '.optim')\n","                        np.save('train.npy', np.array(train_losses))\n","                        np.save('val.npy', np.array(val_losses))\n","                    elif patience < max_patience:\n","                        patience += 1\n","                        print('hit patience %d' % patience)\n","\n","                        if patience == max_patience:\n","                            num_trial += 1\n","                            print('hit #%d trial' % num_trial)\n","                            if num_trial == max_num_trial:\n","                                print('early stop!')\n","                                exit(0)\n","\n","                            # decay lr, and restore from previously best checkpoint\n","                            lr = optimizer.param_groups[0]['lr'] * lr_decay\n","                            print('load previously best model and decay learning rate to %f' % lr)\n","\n","                            # load model\n","                            params = torch.load(model_path, map_location=lambda storage, loc: storage)\n","                            model.load_state_dict(params['state_dict'])\n","                            model = model.to(device)\n","                            train_losses = list(np.load('train.npy', allow_pickle=True))\n","                            val_losses = list(np.load('val.npy', allow_pickle=True))\n","\n","                            print('restore parameters of the optimizers')\n","                            optimizer.load_state_dict(torch.load(model_path + '.optim'))\n","\n","                            # set new lr\n","                            for param_group in optimizer.param_groups:\n","                                param_group['lr'] = lr\n","\n","                            # reset patience\n","                            patience = 0\n","\n","        if epoch == max_epoch:\n","            print('reached maximum number of epochs!')\n","            break"],"id":"kFhfncT-hruW"},{"cell_type":"code","execution_count":null,"metadata":{"id":"3hy4A11xhwzd"},"outputs":[],"source":["# train(train_data, val_data)\n","model = MLP(layer_dims=[1024, 256, 64])\n","params = torch.load('model.bin', map_location=lambda storage, loc: storage)\n","model.load_state_dict(params['state_dict'])\n","model = model.to(device)\n","\n","# article = data[20]['paragraphs']\n","sample = data[200:350]\n","roots = [indexified_tree(model.outline(a['paragraphs'])) for a in sample]\n","golds = [indexified_tree(a['tree'].root) for a in sample]\n","lens = [len(a['paragraphs']) for a in sample]\n","batch_lca_loss(roots, golds, lens)"],"id":"3hy4A11xhwzd"},{"cell_type":"markdown","metadata":{"id":"MUazcP3Jkote"},"source":["##### Human performance"],"id":"MUazcP3Jkote"},{"cell_type":"code","execution_count":null,"metadata":{"id":"2fxv4m2Lkrjp"},"outputs":[],"source":["def get_paragraphs_trees(data):\n","    paras = [d['paragraphs'] for d in data]\n","    trees = [d['tree'] for d in data]\n","    return paras, trees\n","\n","def get_split_data(data, train_ratio=0.05, val_ratio=0.001, test_ratio=0.01):\n","    random.shuffle(data)\n","    n_data = len(data)\n","    train_idx = int(train_ratio*n_data)\n","    val_idx = int((train_ratio + val_ratio)*n_data)\n","    test_idx = int((train_ratio + val_ratio + test_ratio)*n_data)\n","    train_X, train_y = get_paragraphs_trees(data[:train_idx])\n","    val_X, val_y = get_paragraphs_trees(data[train_idx:val_idx])\n","    test_X, test_y = get_paragraphs_trees(data[val_idx:test_idx])\n","    return train_X, train_y, val_X, val_y, test_X, test_y\n","\n","train_X, train_y, val_X, val_y, test_X, test_y = get_split_data(data)"],"id":"2fxv4m2Lkrjp"},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1651533741040,"user":{"displayName":"Michael Tang","userId":"18009171711496870090"},"user_tz":240},"id":"dNKULJxXlK9b","outputId":"63518206-2480-4450-c5ef-4e47366ee7e2"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["[' Olympic record ; NR = National record \\n',\n"," \" Three Egyptian swimmers , one female and two males , qualified for the Olympics . American @-@ born Farida Osman , the woman , was the youngest member of the 2012 national delegation and qualified for the Games based on having made the Olympic Standard Time in the 50 @-@ metre freestyle . In the lead up to the Olympics , she won seven gold medals at the 2011 Pan Arab Games , as well as the 50 @-@ metre butterfly title at that year 's All @-@ Africa Games and World Junior Championships . In London she was sixth in her heat in the 50 @-@ metre freestyle and was eliminated from the tournament , ranking 42nd overall . On the men 's side , <unk> Younis qualified for the 50 @-@ metre freestyle by meeting the Olympic Selection Time of 22 @.@ 88 at an international meet in Eindhoven , Netherlands , with a result of 22 @.@ 85 . Prior to the Olympics he had won a bronze medal in the event at the 2011 Pan Arab Games . In London he was third in his heat and 34th overall , failing to advance to the semifinals . Mazen <unk> , a Saudi @-@ born Egyptian training and studying at Southern Illinois University Carbondale , made the team at an Olympic qualifier in Setúbal , Portugal in June 2012 , the second of his two opportunities ( his first having been the 2011 World Championships ) . At the Games , in the marathon 10 kilometre , he was 24th out of 25 competitors . \\n\",\n"," ' Men \\n',\n"," ' Women \\n',\n"," ' Key : Q \\n']"]},"metadata":{},"execution_count":82}],"source":["test_X[3]"],"id":"dNKULJxXlK9b"},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":17},"executionInfo":{"elapsed":724,"status":"ok","timestamp":1651371101651,"user":{"displayName":"Michael Tang","userId":"07765995532208265709"},"user_tz":240},"id":"CBy8GjAPYONc","outputId":"e8f915e8-ea13-43c7-8a33-4ac1ba48f51b"},"outputs":[{"data":{"application/javascript":["\n","    async function download(id, filename, size) {\n","      if (!google.colab.kernel.accessAllowed) {\n","        return;\n","      }\n","      const div = document.createElement('div');\n","      const label = document.createElement('label');\n","      label.textContent = `Downloading \"${filename}\": `;\n","      div.appendChild(label);\n","      const progress = document.createElement('progress');\n","      progress.max = size;\n","      div.appendChild(progress);\n","      document.body.appendChild(div);\n","\n","      const buffers = [];\n","      let downloaded = 0;\n","\n","      const channel = await google.colab.kernel.comms.open(id);\n","      // Send a message to notify the kernel that we're ready.\n","      channel.send({})\n","\n","      for await (const message of channel.messages) {\n","        // Send a message to notify the kernel that we're ready.\n","        channel.send({})\n","        if (message.buffers) {\n","          for (const buffer of message.buffers) {\n","            buffers.push(buffer);\n","            downloaded += buffer.byteLength;\n","            progress.value = downloaded;\n","          }\n","        }\n","      }\n","      const blob = new Blob(buffers, {type: 'application/binary'});\n","      const a = document.createElement('a');\n","      a.href = window.URL.createObjectURL(blob);\n","      a.download = filename;\n","      div.appendChild(a);\n","      a.click();\n","      div.remove();\n","    }\n","  "],"text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{},"output_type":"display_data"},{"data":{"application/javascript":["download(\"download_aa6d52cd-2048-480f-bf77-49516b228010\", \"test_X.csv\", 5407643)"],"text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{},"output_type":"display_data"}],"source":["import csv\n","from google.colab import files\n","\n","with open(\"test_X.csv\", \"w\") as f:\n","    writer = csv.writer(f)\n","    writer.writerows(test_X)\n","files.download('test_X.csv')"],"id":"CBy8GjAPYONc"},{"cell_type":"code","execution_count":null,"metadata":{"id":"iAKemnWSv4z6"},"outputs":[],"source":["# from tree_utils import *"],"id":"iAKemnWSv4z6"},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":17},"executionInfo":{"elapsed":260,"status":"ok","timestamp":1651444885243,"user":{"displayName":"Michael Tang","userId":"07765995532208265709"},"user_tz":240},"id":"sq53vVSNEwdg","outputId":"ff689c8c-f5e9-4c71-edb7-344a3b455c3a"},"outputs":[{"data":{"application/javascript":["\n","    async function download(id, filename, size) {\n","      if (!google.colab.kernel.accessAllowed) {\n","        return;\n","      }\n","      const div = document.createElement('div');\n","      const label = document.createElement('label');\n","      label.textContent = `Downloading \"${filename}\": `;\n","      div.appendChild(label);\n","      const progress = document.createElement('progress');\n","      progress.max = size;\n","      div.appendChild(progress);\n","      document.body.appendChild(div);\n","\n","      const buffers = [];\n","      let downloaded = 0;\n","\n","      const channel = await google.colab.kernel.comms.open(id);\n","      // Send a message to notify the kernel that we're ready.\n","      channel.send({})\n","\n","      for await (const message of channel.messages) {\n","        // Send a message to notify the kernel that we're ready.\n","        channel.send({})\n","        if (message.buffers) {\n","          for (const buffer of message.buffers) {\n","            buffers.push(buffer);\n","            downloaded += buffer.byteLength;\n","            progress.value = downloaded;\n","          }\n","        }\n","      }\n","      const blob = new Blob(buffers, {type: 'application/binary'});\n","      const a = document.createElement('a');\n","      a.href = window.URL.createObjectURL(blob);\n","      a.download = filename;\n","      div.appendChild(a);\n","      a.click();\n","      div.remove();\n","    }\n","  "],"text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{},"output_type":"display_data"},{"data":{"application/javascript":["download(\"download_47c187a0-d839-4f00-9958-9e93cf703847\", \"test_y.pickle\", 6014345)"],"text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{},"output_type":"display_data"}],"source":["import pickle\n","from google.colab import files\n","\n","with open(\"test_y.pickle\", \"wb\") as f:\n","    pickle.dump(test_y, f)\n","files.download('test_y.pickle')"],"id":"sq53vVSNEwdg"}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":["0ba86871","e49e36c2","FSKtCnA_BdMD"],"name":"All of the updated code as of 6pm saturday 4/30.ipynb","provenance":[{"file_id":"1MGfIx5mwYvwfJTGO2w5ySa7D-1S4-FOd","timestamp":1650353357566}]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.8"},"widgets":{"application/vnd.jupyter.widget-state+json":{"773c05cde4a1423084d64f142850fb1d":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_5a035187b68a4a0e97bfafcd5d0d91e8","IPY_MODEL_a48ee359b4734d87b9ec8f639d04ad23","IPY_MODEL_617dbcb8028c4675b5c48b14fe46f08c"],"layout":"IPY_MODEL_775b015c91494f02bc04279af272ab13"}},"5a035187b68a4a0e97bfafcd5d0d91e8":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6283bf621bb74c64a67e8a6867d39911","placeholder":"​","style":"IPY_MODEL_f4564b7c56c648ad97336aecd26ed33b","value":"Downloading builder script: "}},"a48ee359b4734d87b9ec8f639d04ad23":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_7f6d7177f8914ca6b08d53ed2b67325d","max":2032,"min":0,"orientation":"horizontal","style":"IPY_MODEL_c7bb305976464830b25a298654a64604","value":2032}},"617dbcb8028c4675b5c48b14fe46f08c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_58153034028348caafa8b6c6d1bee89d","placeholder":"​","style":"IPY_MODEL_28573a80e4e84cf98e8440741056b053","value":" 8.48k/? [00:00&lt;00:00, 205kB/s]"}},"775b015c91494f02bc04279af272ab13":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6283bf621bb74c64a67e8a6867d39911":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f4564b7c56c648ad97336aecd26ed33b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7f6d7177f8914ca6b08d53ed2b67325d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c7bb305976464830b25a298654a64604":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"58153034028348caafa8b6c6d1bee89d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"28573a80e4e84cf98e8440741056b053":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ac2ced3866624559875d294050f60152":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_281df3a0fc9341b3a1fba2ed4efa930e","IPY_MODEL_ced9c087cf724e47a74f6211a013d351","IPY_MODEL_cbfc2c011d3e427883520fcfa996a271"],"layout":"IPY_MODEL_43c7e087e9564d8d9477806887c484f9"}},"281df3a0fc9341b3a1fba2ed4efa930e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_815ba480181349dd825187d2cef43aa8","placeholder":"​","style":"IPY_MODEL_54ac043dc38f4bb4957f4d7f7657b994","value":"Downloading metadata: "}},"ced9c087cf724e47a74f6211a013d351":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_60b755cd7e7a41ecbc56153205cd1ac0","max":1250,"min":0,"orientation":"horizontal","style":"IPY_MODEL_03a4f14226464f908f54aded4531ee08","value":1250}},"cbfc2c011d3e427883520fcfa996a271":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_fc1d31374d4e4385a0f978a2d1e36e8b","placeholder":"​","style":"IPY_MODEL_121f83539f8a4b26931ecb5feb5e3977","value":" 6.84k/? [00:00&lt;00:00, 160kB/s]"}},"43c7e087e9564d8d9477806887c484f9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"815ba480181349dd825187d2cef43aa8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"54ac043dc38f4bb4957f4d7f7657b994":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"60b755cd7e7a41ecbc56153205cd1ac0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"03a4f14226464f908f54aded4531ee08":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"fc1d31374d4e4385a0f978a2d1e36e8b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"121f83539f8a4b26931ecb5feb5e3977":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"25f34817536b49dca5ec9885360f7dd0":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_f8f2ea1cbfb643ccb94f40049654ca86","IPY_MODEL_9732984f8eec46c9b5213c7d8caf8aeb","IPY_MODEL_ea7f1b60234e4348b9920936ab199116"],"layout":"IPY_MODEL_246a5ad76b5e46678f44c9b595622ac4"}},"f8f2ea1cbfb643ccb94f40049654ca86":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5200df879aa5458f9ba6e1d8da9f551d","placeholder":"​","style":"IPY_MODEL_fa7b28759a9f4d7784c403f11615aa3c","value":"Downloading data: 100%"}},"9732984f8eec46c9b5213c7d8caf8aeb":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_7d77a583d7fc422ea465c646b1d418f9","max":190229076,"min":0,"orientation":"horizontal","style":"IPY_MODEL_4b43456002264dbda81e4f3ce5e15e38","value":190229076}},"ea7f1b60234e4348b9920936ab199116":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ef7743c0475040c3bbc62e24f144534b","placeholder":"​","style":"IPY_MODEL_fed88e05d29d4eaf9bb9a7fbe91e8fcd","value":" 190M/190M [00:15&lt;00:00, 14.6MB/s]"}},"246a5ad76b5e46678f44c9b595622ac4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5200df879aa5458f9ba6e1d8da9f551d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fa7b28759a9f4d7784c403f11615aa3c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7d77a583d7fc422ea465c646b1d418f9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4b43456002264dbda81e4f3ce5e15e38":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"ef7743c0475040c3bbc62e24f144534b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fed88e05d29d4eaf9bb9a7fbe91e8fcd":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"23fcd87df73a417294b1276d5bdd5ac1":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_e04edd5502644d47b931910271d238ba","IPY_MODEL_308a4b948cd84ba492a45d5892233c21","IPY_MODEL_d2f00a6d90dd47d290fc754fecc6a4b1"],"layout":"IPY_MODEL_9fd0a1596ed04a0c8be5e81f65ea01e0"}},"e04edd5502644d47b931910271d238ba":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e5b5591d62e54a238880fb1acb6dcf4d","placeholder":"​","style":"IPY_MODEL_9353f028be9446b4adf08246b2c369d9","value":"Generating test split:  31%"}},"308a4b948cd84ba492a45d5892233c21":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_acb06e8008fb4260a78c5472afcbf0e6","max":4358,"min":0,"orientation":"horizontal","style":"IPY_MODEL_c376ae4317984cd685aea994822a499e","value":4358}},"d2f00a6d90dd47d290fc754fecc6a4b1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_76e3856ed53e48aea8e8ba8d506cb7b4","placeholder":"​","style":"IPY_MODEL_6f5551025d1b44dcac4f68dbd4f194d8","value":" 1331/4358 [00:00&lt;00:00, 13308.93 examples/s]"}},"9fd0a1596ed04a0c8be5e81f65ea01e0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e5b5591d62e54a238880fb1acb6dcf4d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9353f028be9446b4adf08246b2c369d9":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"acb06e8008fb4260a78c5472afcbf0e6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c376ae4317984cd685aea994822a499e":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"76e3856ed53e48aea8e8ba8d506cb7b4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6f5551025d1b44dcac4f68dbd4f194d8":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8577544779b84b0b89148142a95384cd":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_6b7ef23c58d945cea9187fa9388c37e8","IPY_MODEL_cb771726df0b48d7a761901434b125cd","IPY_MODEL_6d5a0ac5920d417282f359a0c8b06baf"],"layout":"IPY_MODEL_ea50b4f5786347649809f72f76295684"}},"6b7ef23c58d945cea9187fa9388c37e8":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_bbf48b5c77684dd19033e3435435045d","placeholder":"​","style":"IPY_MODEL_b6a309452d6a4355a405ed2dd1adae82","value":"Generating train split: 100%"}},"cb771726df0b48d7a761901434b125cd":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_2a20a51c8b214be896e710cf49218ee4","max":1801350,"min":0,"orientation":"horizontal","style":"IPY_MODEL_554c9581fc654bfab759605a135179fb","value":1801350}},"6d5a0ac5920d417282f359a0c8b06baf":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_83c598bf65c5414a94806ef20cf693fc","placeholder":"​","style":"IPY_MODEL_3137f59faf16438eaff31e134bd719bf","value":" 1798868/1801350 [00:56&lt;00:00, 31703.67 examples/s]"}},"ea50b4f5786347649809f72f76295684":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bbf48b5c77684dd19033e3435435045d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b6a309452d6a4355a405ed2dd1adae82":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2a20a51c8b214be896e710cf49218ee4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"554c9581fc654bfab759605a135179fb":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"83c598bf65c5414a94806ef20cf693fc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3137f59faf16438eaff31e134bd719bf":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"38736a24e576459c93e31f35192abe10":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_6555fb7e67614def8396ee1ed8e7a96e","IPY_MODEL_8ec81ddfdd1947d098dfd905a19a65bb","IPY_MODEL_bf10e5be7bae432395134f7baaf8ab18"],"layout":"IPY_MODEL_f905ad9adce24720a615e1ae9113fab8"}},"6555fb7e67614def8396ee1ed8e7a96e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_328d7ceac2374478b88d1b7fd979ce36","placeholder":"​","style":"IPY_MODEL_4d12722f87fc45fa94a5330a48830a2a","value":"Generating validation split:  33%"}},"8ec81ddfdd1947d098dfd905a19a65bb":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_0396dc796df344a29814e80aac8bf309","max":3760,"min":0,"orientation":"horizontal","style":"IPY_MODEL_b4e8e94f0fc949129ad2a824edfc5873","value":3760}},"bf10e5be7bae432395134f7baaf8ab18":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5c4bc994762c446ba9189109c426999c","placeholder":"​","style":"IPY_MODEL_d070834acdb643cb853fa60f8ebc7aec","value":" 1242/3760 [00:00&lt;00:00, 12418.03 examples/s]"}},"f905ad9adce24720a615e1ae9113fab8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"328d7ceac2374478b88d1b7fd979ce36":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4d12722f87fc45fa94a5330a48830a2a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0396dc796df344a29814e80aac8bf309":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b4e8e94f0fc949129ad2a824edfc5873":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"5c4bc994762c446ba9189109c426999c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d070834acdb643cb853fa60f8ebc7aec":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ef2bc51cf1a84b1ca856c4e265879cf5":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_85cf1d77f0924327a1eb95afc7fd3011","IPY_MODEL_3895e3a6bec444eabe862f82249b319c","IPY_MODEL_9708ea704f4b4f4cbfb52ef3533f05ed"],"layout":"IPY_MODEL_8eb0742b4d1048e4a1ee11913bd3cdbf"}},"85cf1d77f0924327a1eb95afc7fd3011":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_25faf5e68c454d3e9ded128f3a1a537e","placeholder":"​","style":"IPY_MODEL_d705ca2543544fe4a7aec25c1a5a53ca","value":"Downloading: 100%"}},"3895e3a6bec444eabe862f82249b319c":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_d697581694454f588965a608fb5b5e02","max":252,"min":0,"orientation":"horizontal","style":"IPY_MODEL_413c070a006a46bfa9125bfb93fc1a0b","value":252}},"9708ea704f4b4f4cbfb52ef3533f05ed":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_59c0542f6cb34181b1d2e7010bffe36e","placeholder":"​","style":"IPY_MODEL_172d08811d284c138881787a07859fd3","value":" 252/252 [00:00&lt;00:00, 2.51kB/s]"}},"8eb0742b4d1048e4a1ee11913bd3cdbf":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"25faf5e68c454d3e9ded128f3a1a537e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d705ca2543544fe4a7aec25c1a5a53ca":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d697581694454f588965a608fb5b5e02":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"413c070a006a46bfa9125bfb93fc1a0b":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"59c0542f6cb34181b1d2e7010bffe36e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"172d08811d284c138881787a07859fd3":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"224ab8eedf1d436083fd2bf54bc1a9d9":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_2176a90bbe5d47069b5d5f44e08b8ac2","IPY_MODEL_b44f1e298fce4d1d8d25b5efa006af64","IPY_MODEL_3c0fcc03e47740f09c7462cb3190188f"],"layout":"IPY_MODEL_6d4926ec931647b684fae41439ffcd1a"}},"2176a90bbe5d47069b5d5f44e08b8ac2":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f3c16b5087924db38083f9ecc4c3fd25","placeholder":"​","style":"IPY_MODEL_65852eadf5394ba0a3b088937ea48651","value":"Downloading: 100%"}},"b44f1e298fce4d1d8d25b5efa006af64":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_128db6e92c2f480d8e682913538c28a5","max":689,"min":0,"orientation":"horizontal","style":"IPY_MODEL_15f96380e4bf45c59310f39b3c7dc10c","value":689}},"3c0fcc03e47740f09c7462cb3190188f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a3aa988f39c9463a978171fe47b1d022","placeholder":"​","style":"IPY_MODEL_f963ceae2bb44d66b951cb8f20c76a78","value":" 689/689 [00:00&lt;00:00, 7.75kB/s]"}},"6d4926ec931647b684fae41439ffcd1a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f3c16b5087924db38083f9ecc4c3fd25":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"65852eadf5394ba0a3b088937ea48651":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"128db6e92c2f480d8e682913538c28a5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"15f96380e4bf45c59310f39b3c7dc10c":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"a3aa988f39c9463a978171fe47b1d022":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f963ceae2bb44d66b951cb8f20c76a78":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"58c6ff8c2944417f985d2e6bb6a539cf":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_2f716f49f76e4d51a0fc81cc4e9d1002","IPY_MODEL_05c5f215ed7d43d3b7b5485c9a2da38f","IPY_MODEL_6cdb0e41acee4351add7fe639ca8a591"],"layout":"IPY_MODEL_ad4139224d064426abff47547e5e8927"}},"2f716f49f76e4d51a0fc81cc4e9d1002":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ad4cef694b7e43e188393ee353796f2c","placeholder":"​","style":"IPY_MODEL_e94be5614c4a4eeb832b4f1f3cb4c418","value":"Downloading: 100%"}},"05c5f215ed7d43d3b7b5485c9a2da38f":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_f4479572e309462d96d13122ccf24e3a","max":231508,"min":0,"orientation":"horizontal","style":"IPY_MODEL_60e74ade881f4c11b6f47bd5777c2e21","value":231508}},"6cdb0e41acee4351add7fe639ca8a591":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_20a73804ccad418a8c02cd878680aa19","placeholder":"​","style":"IPY_MODEL_651f69f0e1b44e66acdae3edd30c631b","value":" 226k/226k [00:00&lt;00:00, 339kB/s]"}},"ad4139224d064426abff47547e5e8927":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ad4cef694b7e43e188393ee353796f2c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e94be5614c4a4eeb832b4f1f3cb4c418":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f4479572e309462d96d13122ccf24e3a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"60e74ade881f4c11b6f47bd5777c2e21":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"20a73804ccad418a8c02cd878680aa19":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"651f69f0e1b44e66acdae3edd30c631b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8fcb5f59868e47a2b3e5276b481630e9":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_0a610eee469f41888a6e4455ffbc8018","IPY_MODEL_606f1faa202d4a788d254832e7f61dbb","IPY_MODEL_5066f23abdc0484b8c80faa56b022872"],"layout":"IPY_MODEL_ea7ac9d8672a45ceb82db8b3385fa8df"}},"0a610eee469f41888a6e4455ffbc8018":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f58aef5744db4c1e8e4048a99562687f","placeholder":"​","style":"IPY_MODEL_bc20ab5ab26b407ea31d84ed96cff1d2","value":"Downloading: 100%"}},"606f1faa202d4a788d254832e7f61dbb":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_866b50cc44d4466c9faec5724eafa112","max":112,"min":0,"orientation":"horizontal","style":"IPY_MODEL_e1e03e4c95d24426badad309112f27de","value":112}},"5066f23abdc0484b8c80faa56b022872":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_fa0e2ddcc81e476499c34910a3cdd184","placeholder":"​","style":"IPY_MODEL_ba143d5633884e258e366af7c5fc8742","value":" 112/112 [00:00&lt;00:00, 829B/s]"}},"ea7ac9d8672a45ceb82db8b3385fa8df":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f58aef5744db4c1e8e4048a99562687f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bc20ab5ab26b407ea31d84ed96cff1d2":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"866b50cc44d4466c9faec5724eafa112":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e1e03e4c95d24426badad309112f27de":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"fa0e2ddcc81e476499c34910a3cdd184":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ba143d5633884e258e366af7c5fc8742":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f635f543ed3343cabb57e4cc47dcb0d0":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_eb7b58eace194f739177fc7afb6e61c1","IPY_MODEL_ab7b8c1bbb1045a0a0572f4489a20bda","IPY_MODEL_714e39edacbb4986947fb5ded0945149"],"layout":"IPY_MODEL_d7f49f3c81f843999972c334434b90fa"}},"eb7b58eace194f739177fc7afb6e61c1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_dcc30d7944a34fc0bbd64844620d9e78","placeholder":"​","style":"IPY_MODEL_629a769e931f45acb6727bbe203aa4a2","value":"Downloading: 100%"}},"ab7b8c1bbb1045a0a0572f4489a20bda":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_204e29c8a78e4be3bd33432c86de43c9","max":437998343,"min":0,"orientation":"horizontal","style":"IPY_MODEL_23c1777fb6bd4c11afec127b45c24e06","value":437998343}},"714e39edacbb4986947fb5ded0945149":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6c149eb091c84007ac2935c1262b5695","placeholder":"​","style":"IPY_MODEL_4e5ee2f003e94e3083a19c450db40ad1","value":" 418M/418M [00:22&lt;00:00, 37.4MB/s]"}},"d7f49f3c81f843999972c334434b90fa":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dcc30d7944a34fc0bbd64844620d9e78":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"629a769e931f45acb6727bbe203aa4a2":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"204e29c8a78e4be3bd33432c86de43c9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"23c1777fb6bd4c11afec127b45c24e06":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"6c149eb091c84007ac2935c1262b5695":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4e5ee2f003e94e3083a19c450db40ad1":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":5}